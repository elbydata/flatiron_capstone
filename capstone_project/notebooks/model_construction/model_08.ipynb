{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 8: Additional Capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the construction and training of the model iterations and various experiments. The notebook is split up into four sections: training mode selection (where the model will run), set-up, model constrution, and training. \n",
    "\n",
    "Evaluation will take place in the *model_optimization_and_evaluation.ipynb* notebook found in the *notebooks* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import applications \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Training Mode Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, specify the training mode for the model. This will determine the location from which the source data is drawn, and to which the trained models (and training histories) are saved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **training_mode = 'floydhub'** (runs on Floydhub)\n",
    "- **training_mode = 'local'** (runs on local disk and processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select training mode\n",
    "training_mode = 'floydhub'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory base paths\n",
    "data_path_local = '../../data/0002_array_data/train_data/'\n",
    "model_path_local = '../../notebooks/model_construction/saved_models/'\n",
    "data_path_floydhub = '/floyd/input/capstone_mushrooms/'\n",
    "model_path_floydhub = '/floyd/home/'\n",
    "\n",
    "# setting directory paths based on training mode selection\n",
    "if training_mode == 'floydhub':\n",
    "    data_path = data_path_floydhub\n",
    "    model_path = model_path_floydhub\n",
    "elif training_mode == 'local':\n",
    "    data_path = data_path_local\n",
    "    model_path = model_path_local\n",
    "else:\n",
    "    raise Exception('Please choose valid training mode: \"floydhub\" or \"local\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the training and validation data subsets\n",
    "X_train = np.load(f'{data_path}X_train_data.npy')\n",
    "y_train = np.load(f'{data_path}y_train_data.npy')\n",
    "X_val = np.load(f'{data_path}X_val_data.npy')\n",
    "y_val = np.load(f'{data_path}y_val_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting training parameters\n",
    "batch_size = 8\n",
    "n_classes = 20\n",
    "n_epochs = 30\n",
    "img_shape = X_train.shape[1:]\n",
    "model_names = []\n",
    "model_list = []\n",
    "model_hists = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 1 - Additional convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                20500     \n",
      "=================================================================\n",
      "Total params: 20,464,468\n",
      "Trainable params: 20,464,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m8_t1 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m8_t1.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same'))\n",
    "m8_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m8_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m8_t1.add(layers.Conv2D(64,(3,3), padding='same'))\n",
    "m8_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m8_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m8_t1.add(layers.Conv2D(128,(3,3), padding='same'))\n",
    "m8_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m8_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m8_t1.add(layers.Conv2D(256,(3,3), padding='same'))\n",
    "m8_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m8_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m8_t1.add(layers.Conv2D(512,(3,3), padding='same'))\n",
    "m8_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m8_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m8_t1.add(layers.Flatten())\n",
    "m8_t1.add(layers.Dense(1024))\n",
    "m8_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m8_t1.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m8_t1.summary()\n",
    "model_names.append('m8_t1')\n",
    "model_list.append(m8_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 2 - Additional convolutions and replacing final max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                20500     \n",
      "=================================================================\n",
      "Total params: 22,824,276\n",
      "Trainable params: 22,824,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m8_t2 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m8_t2.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same'))\n",
    "m8_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m8_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m8_t2.add(layers.Conv2D(64,(3,3), padding='same'))\n",
    "m8_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m8_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m8_t2.add(layers.Conv2D(128,(3,3), padding='same'))\n",
    "m8_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m8_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m8_t2.add(layers.Conv2D(256,(3,3), padding='same'))\n",
    "m8_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m8_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m8_t2.add(layers.Conv2D(512,(3,3), padding='same'))\n",
    "m8_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m8_t2.add(layers.Conv2D(512,(3,3), strides=2, padding='same'))\n",
    "m8_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "\n",
    "# fully connected layers\n",
    "m8_t2.add(layers.Flatten())\n",
    "m8_t2.add(layers.Dense(1024))\n",
    "m8_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m8_t2.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m8_t2.summary()\n",
    "model_names.append('m8_t2')\n",
    "model_list.append(m8_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up standardization and augmentation parameters\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.3,\n",
    "                                   height_shift_range=0.3,\n",
    "                                   shear_range=0.3,\n",
    "                                   zoom_range=0.3,\n",
    "                                   fill_mode='nearest',\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 329 ms, sys: 1.03 s, total: 1.36 s\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data standardization and augmentation\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling loss functions\n",
    "m8_t1.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['acc'])\n",
    "m8_t2.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 2.6873 - acc: 0.1356 - val_loss: 1.7893 - val_acc: 0.2277\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.22772, saving model to /floyd/home/m8_t1.h5\n",
      "Epoch 2/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.3853 - acc: 0.2293 - val_loss: 3.0106 - val_acc: 0.3017\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.22772 to 0.30175, saving model to /floyd/home/m8_t1.h5\n",
      "Epoch 3/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.2298 - acc: 0.2756 - val_loss: 2.5752 - val_acc: 0.4127\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.30175 to 0.41272, saving model to /floyd/home/m8_t1.h5\n",
      "Epoch 4/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.1163 - acc: 0.3189 - val_loss: 1.9225 - val_acc: 0.4177\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.41272 to 0.41771, saving model to /floyd/home/m8_t1.h5\n",
      "Epoch 5/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.0124 - acc: 0.3588 - val_loss: 1.5566 - val_acc: 0.4476\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.41771 to 0.44763, saving model to /floyd/home/m8_t1.h5\n",
      "Epoch 6/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 1.9634 - acc: 0.3770 - val_loss: 1.6558 - val_acc: 0.4264\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.44763\n",
      "Epoch 7/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.8648 - acc: 0.3994 - val_loss: 2.0762 - val_acc: 0.4738\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.44763 to 0.47382, saving model to /floyd/home/m8_t1.h5\n",
      "Epoch 8/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.8202 - acc: 0.4195 - val_loss: 2.0482 - val_acc: 0.5337\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.47382 to 0.53367, saving model to /floyd/home/m8_t1.h5\n",
      "Epoch 9/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.7482 - acc: 0.4470 - val_loss: 1.5818 - val_acc: 0.5299\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.53367\n",
      "Epoch 10/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.6962 - acc: 0.4584 - val_loss: 1.3694 - val_acc: 0.4988\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.53367\n",
      "Epoch 11/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6302 - acc: 0.4717 - val_loss: 1.1417 - val_acc: 0.5773\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.53367 to 0.57731, saving model to /floyd/home/m8_t1.h5\n",
      "Epoch 12/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.5873 - acc: 0.4996 - val_loss: 1.7693 - val_acc: 0.5461\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.57731\n",
      "Epoch 13/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.5349 - acc: 0.5112 - val_loss: 0.7666 - val_acc: 0.5474\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.57731\n",
      "Epoch 14/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.4948 - acc: 0.5236 - val_loss: 1.7832 - val_acc: 0.6110\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.57731 to 0.61097, saving model to /floyd/home/m8_t1.h5\n",
      "Epoch 15/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.4709 - acc: 0.5258 - val_loss: 1.7148 - val_acc: 0.6010\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.61097\n",
      "Epoch 16/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.4139 - acc: 0.5506 - val_loss: 1.7020 - val_acc: 0.5374\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.61097\n",
      "Epoch 17/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.3924 - acc: 0.5623 - val_loss: 1.1872 - val_acc: 0.6197\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.61097 to 0.61970, saving model to /floyd/home/m8_t1.h5\n",
      "Epoch 18/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.3563 - acc: 0.5673 - val_loss: 0.7199 - val_acc: 0.6384\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.61970 to 0.63840, saving model to /floyd/home/m8_t1.h5\n",
      "Epoch 19/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.3215 - acc: 0.5820 - val_loss: 0.8040 - val_acc: 0.6397\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.63840 to 0.63965, saving model to /floyd/home/m8_t1.h5\n",
      "Epoch 20/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.3016 - acc: 0.5890 - val_loss: 1.2076 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.63965 to 0.65835, saving model to /floyd/home/m8_t1.h5\n",
      "Epoch 21/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.2724 - acc: 0.5964 - val_loss: 0.2658 - val_acc: 0.5910\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.65835\n",
      "Epoch 22/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.2474 - acc: 0.6026 - val_loss: 2.3072 - val_acc: 0.5299\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.65835\n",
      "Epoch 23/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.2177 - acc: 0.6104 - val_loss: 1.4035 - val_acc: 0.6297\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.65835\n",
      "Epoch 24/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.1833 - acc: 0.6221 - val_loss: 1.9219 - val_acc: 0.6696\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.65835 to 0.66958, saving model to /floyd/home/m8_t1.h5\n",
      "Epoch 25/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.1493 - acc: 0.6356 - val_loss: 0.8377 - val_acc: 0.6571\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.66958\n",
      "Epoch 26/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.1363 - acc: 0.6393 - val_loss: 1.1916 - val_acc: 0.6509\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.66958\n",
      "Epoch 27/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.1143 - acc: 0.6443 - val_loss: 0.1957 - val_acc: 0.6858\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.66958 to 0.68579, saving model to /floyd/home/m8_t1.h5\n",
      "Epoch 28/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.0929 - acc: 0.6543 - val_loss: 0.3332 - val_acc: 0.6721\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.68579\n",
      "Epoch 29/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.0841 - acc: 0.6533 - val_loss: 0.8711 - val_acc: 0.6671\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.68579\n",
      "Epoch 30/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.0644 - acc: 0.6638 - val_loss: 1.2137 - val_acc: 0.7070\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.68579 to 0.70698, saving model to /floyd/home/m8_t1.h5\n",
      "CPU times: user 56min 22s, sys: 6min 52s, total: 1h 3min 14s\n",
      "Wall time: 39min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m8_t1_cp = ModelCheckpoint(filepath=f'{model_path}m8_t1.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m8_t1_history = m8_t1.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m8_t1_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m8_t1_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.7914 - acc: 0.1095 - val_loss: 2.5518 - val_acc: 0.1708\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.17079, saving model to /floyd/home/m8_t2.h5\n",
      "Epoch 2/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 2.5627 - acc: 0.1591 - val_loss: 2.2397 - val_acc: 0.2095\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.17079 to 0.20948, saving model to /floyd/home/m8_t2.h5\n",
      "Epoch 3/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.4284 - acc: 0.2036 - val_loss: 2.1590 - val_acc: 0.2032\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.20948\n",
      "Epoch 4/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 2.3058 - acc: 0.2522 - val_loss: 2.1109 - val_acc: 0.2618\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.20948 to 0.26185, saving model to /floyd/home/m8_t2.h5\n",
      "Epoch 5/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 2.1857 - acc: 0.2865 - val_loss: 2.2449 - val_acc: 0.3392\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.26185 to 0.33915, saving model to /floyd/home/m8_t2.h5\n",
      "Epoch 6/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 2.0950 - acc: 0.3232 - val_loss: 3.9988 - val_acc: 0.3404\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.33915 to 0.34040, saving model to /floyd/home/m8_t2.h5\n",
      "Epoch 7/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.0116 - acc: 0.3558 - val_loss: 1.5075 - val_acc: 0.4227\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.34040 to 0.42269, saving model to /floyd/home/m8_t2.h5\n",
      "Epoch 8/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 1.9501 - acc: 0.3717 - val_loss: 1.9913 - val_acc: 0.4788\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.42269 to 0.47880, saving model to /floyd/home/m8_t2.h5\n",
      "Epoch 9/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.8835 - acc: 0.4006 - val_loss: 2.3352 - val_acc: 0.4613\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.47880\n",
      "Epoch 10/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 1.8403 - acc: 0.4190 - val_loss: 1.0402 - val_acc: 0.4850\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.47880 to 0.48504, saving model to /floyd/home/m8_t2.h5\n",
      "Epoch 11/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 1.7847 - acc: 0.4301 - val_loss: 2.0379 - val_acc: 0.5274\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.48504 to 0.52743, saving model to /floyd/home/m8_t2.h5\n",
      "Epoch 12/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 1.7410 - acc: 0.4423 - val_loss: 1.6303 - val_acc: 0.5087\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.52743\n",
      "Epoch 13/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.6926 - acc: 0.4581 - val_loss: 0.6449 - val_acc: 0.5050\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.52743\n",
      "Epoch 14/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.6227 - acc: 0.4856 - val_loss: 1.6416 - val_acc: 0.5187\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.52743\n",
      "Epoch 15/30\n",
      "1013/1013 [==============================] - 81s 80ms/step - loss: 1.6094 - acc: 0.4911 - val_loss: 1.0829 - val_acc: 0.5424\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.52743 to 0.54239, saving model to /floyd/home/m8_t2.h5\n",
      "Epoch 16/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 1.5578 - acc: 0.5065 - val_loss: 1.8920 - val_acc: 0.5786\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.54239 to 0.57855, saving model to /floyd/home/m8_t2.h5\n",
      "Epoch 17/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 1.5265 - acc: 0.5188 - val_loss: 1.4628 - val_acc: 0.5960\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.57855 to 0.59601, saving model to /floyd/home/m8_t2.h5\n",
      "Epoch 18/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 1.5004 - acc: 0.5185 - val_loss: 0.8582 - val_acc: 0.5786\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.59601\n",
      "Epoch 19/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 1.4548 - acc: 0.5405 - val_loss: 1.7432 - val_acc: 0.6197\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.59601 to 0.61970, saving model to /floyd/home/m8_t2.h5\n",
      "Epoch 20/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.4296 - acc: 0.5498 - val_loss: 1.2088 - val_acc: 0.6185\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.61970\n",
      "Epoch 21/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 1.3790 - acc: 0.5643 - val_loss: 0.7634 - val_acc: 0.6197\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.61970\n",
      "Epoch 22/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.3825 - acc: 0.5600 - val_loss: 0.7466 - val_acc: 0.6135\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.61970\n",
      "Epoch 23/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 1.3427 - acc: 0.5731 - val_loss: 3.2230 - val_acc: 0.5973\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.61970\n",
      "Epoch 24/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.2940 - acc: 0.5912 - val_loss: 0.6981 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.61970 to 0.64713, saving model to /floyd/home/m8_t2.h5\n",
      "Epoch 25/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 1.2878 - acc: 0.5931 - val_loss: 0.5321 - val_acc: 0.5773\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.64713\n",
      "Epoch 26/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.2760 - acc: 0.6015 - val_loss: 2.0692 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.64713 to 0.64963, saving model to /floyd/home/m8_t2.h5\n",
      "Epoch 27/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 1.2592 - acc: 0.5973 - val_loss: 1.2181 - val_acc: 0.6135\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.64963\n",
      "Epoch 28/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.2297 - acc: 0.6098 - val_loss: 1.1220 - val_acc: 0.6035\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.64963\n",
      "Epoch 29/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.2200 - acc: 0.6137 - val_loss: 0.4979 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.64963\n",
      "Epoch 30/30\n",
      "1013/1013 [==============================] - 80s 79ms/step - loss: 1.1986 - acc: 0.6284 - val_loss: 1.8218 - val_acc: 0.5898\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.64963\n",
      "CPU times: user 58min 49s, sys: 7min 56s, total: 1h 6min 45s\n",
      "Wall time: 40min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m8_t2_cp = ModelCheckpoint(filepath=f'{model_path}m8_t2.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m8_t2_history = m8_t2.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m8_t2_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m8_t2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary for model names, models, and histories from respective lists\n",
    "models_dict = {i:[j,k] for i,j,k in zip(model_names,model_list,model_hists)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 2s 20ms/step\n",
      "m8_t1 Val Accuracy: 70.25%\n",
      "m8_t1 Val Loss: 0.1861\n",
      "---\n",
      "102/102 [==============================] - 2s 21ms/step\n",
      "m8_t2 Val Accuracy: 64.07%\n",
      "m8_t2 Val Loss: 0.0824\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# evaluating models on validation set\n",
    "for key, value in models_dict.items():\n",
    "    model = models.load_model(f'{model_path}{key}.h5')\n",
    "    (val_loss, val_accuracy) = model.evaluate(val_generator,verbose=1)\n",
    "    print(f'{key} Val Accuracy: {round((val_accuracy*100),2)}%')\n",
    "    print(f'{key} Val Loss: {round(val_loss,4)}')\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m8_t1_history saved in /floyd/home/\n",
      "m8_t2_history saved in /floyd/home/\n"
     ]
    }
   ],
   "source": [
    "# saving training histories\n",
    "for key, value in models_dict.items():\n",
    "    with open(f'{model_path}{key}_history', 'wb') as file_pi:\n",
    "        pickle.dump(value[1].history, file_pi)\n",
    "    print(f'{key}_history saved in {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
