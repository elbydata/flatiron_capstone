{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6: Kernel Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the construction and training of the model iterations and various experiments. The notebook is split up into four sections: training mode selection (where the model will run), set-up, model constrution, and training. \n",
    "\n",
    "Evaluation will take place in the *model_optimization_and_evaluation.ipynb* notebook found in the *notebooks* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import applications \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Training Mode Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, specify the training mode for the model. This will determine the location from which the source data is drawn, and to which the trained models (and training histories) are saved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **training_mode = 'floydhub'** (runs on Floydhub)\n",
    "- **training_mode = 'local'** (runs on local disk and processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select training mode\n",
    "training_mode = 'floydhub'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory base paths\n",
    "data_path_local = '../../data/0002_array_data/train_data/'\n",
    "model_path_local = '../../notebooks/model_construction/saved_models/'\n",
    "data_path_floydhub = '/floyd/input/capstone_mushrooms/'\n",
    "model_path_floydhub = '/floyd/home/'\n",
    "\n",
    "# setting directory paths based on training mode selection\n",
    "if training_mode == 'floydhub':\n",
    "    data_path = data_path_floydhub\n",
    "    model_path = model_path_floydhub\n",
    "elif training_mode == 'local':\n",
    "    data_path = data_path_local\n",
    "    model_path = model_path_local\n",
    "else:\n",
    "    raise Exception('Please choose valid training mode: \"floydhub\" or \"local\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the training and validation data subsets\n",
    "X_train = np.load(f'{data_path}X_train_data.npy')\n",
    "y_train = np.load(f'{data_path}y_train_data.npy')\n",
    "X_val = np.load(f'{data_path}X_val_data.npy')\n",
    "y_val = np.load(f'{data_path}y_val_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting training parameters\n",
    "batch_size = 8\n",
    "n_classes = 20\n",
    "n_epochs = 30\n",
    "img_shape = X_train.shape[1:]\n",
    "model_names = []\n",
    "model_list = []\n",
    "model_hists = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 1 - Glorot Normal Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m6_t1 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m6_t1.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same', kernel_initializer='glorot_normal'))\n",
    "m6_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m6_t1.add(layers.Conv2D(64,(3,3), padding='same', kernel_initializer='glorot_normal'))\n",
    "m6_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m6_t1.add(layers.Conv2D(128,(3,3), padding='same', kernel_initializer='glorot_normal'))\n",
    "m6_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m6_t1.add(layers.Conv2D(256,(3,3), padding='same', kernel_initializer='glorot_normal'))\n",
    "m6_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m6_t1.add(layers.Flatten())\n",
    "m6_t1.add(layers.Dense(512, kernel_initializer='glorot_normal'))\n",
    "m6_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t1.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m6_t1.summary()\n",
    "model_names.append('m6_t1')\n",
    "model_list.append(m6_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 2 - Glorot Uniform Initialization (model_05 re-run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m6_t2 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m6_t2.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same', kernel_initializer='glorot_uniform'))\n",
    "m6_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m6_t2.add(layers.Conv2D(64,(3,3), padding='same', kernel_initializer='glorot_uniform'))\n",
    "m6_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m6_t2.add(layers.Conv2D(128,(3,3), padding='same', kernel_initializer='glorot_uniform'))\n",
    "m6_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m6_t2.add(layers.Conv2D(256,(3,3), padding='same', kernel_initializer='glorot_uniform'))\n",
    "m6_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m6_t2.add(layers.Flatten())\n",
    "m6_t2.add(layers.Dense(512, kernel_initializer='glorot_uniform'))\n",
    "m6_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t2.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m6_t2.summary()\n",
    "model_names.append('m6_t2')\n",
    "model_list.append(m6_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 3 - He Normal Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m6_t3 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m6_t3.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same', kernel_initializer='he_normal'))\n",
    "m6_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m6_t3.add(layers.Conv2D(64,(3,3), padding='same', kernel_initializer='he_normal'))\n",
    "m6_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m6_t3.add(layers.Conv2D(128,(3,3), padding='same', kernel_initializer='he_normal'))\n",
    "m6_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m6_t3.add(layers.Conv2D(256,(3,3), padding='same', kernel_initializer='he_normal'))\n",
    "m6_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m6_t3.add(layers.Flatten())\n",
    "m6_t3.add(layers.Dense(512, kernel_initializer='he_normal'))\n",
    "m6_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t3.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m6_t3.summary()\n",
    "model_names.append('m6_t3')\n",
    "model_list.append(m6_t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 4 - He Uniform Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m6_t4 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m6_t4.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same', kernel_initializer='he_uniform'))\n",
    "m6_t4.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m6_t4.add(layers.Conv2D(64,(3,3), padding='same', kernel_initializer='he_uniform'))\n",
    "m6_t4.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m6_t4.add(layers.Conv2D(128,(3,3), padding='same', kernel_initializer='he_uniform'))\n",
    "m6_t4.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m6_t4.add(layers.Conv2D(256,(3,3), padding='same', kernel_initializer='he_uniform'))\n",
    "m6_t4.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m6_t4.add(layers.Flatten())\n",
    "m6_t4.add(layers.Dense(512, kernel_initializer='he_uniform'))\n",
    "m6_t4.add(layers.LeakyReLU(alpha=0.1))\n",
    "m6_t4.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m6_t4.summary()\n",
    "model_names.append('m6_t4')\n",
    "model_list.append(m6_t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up standardization and augmentation parameters\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.3,\n",
    "                                   height_shift_range=0.3,\n",
    "                                   shear_range=0.3,\n",
    "                                   zoom_range=0.3,\n",
    "                                   fill_mode='nearest',\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 403 ms, sys: 861 ms, total: 1.26 s\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data standardization and augmentation\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling loss functions\n",
    "m6_t1.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['acc'])\n",
    "m6_t2.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['acc'])\n",
    "m6_t3.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['acc'])\n",
    "m6_t4.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 2.6710 - acc: 0.1541 - val_loss: 2.6768 - val_acc: 0.2822\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.28218, saving model to /floyd/home/m6_t1.h5\n",
      "Epoch 2/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 2.3122 - acc: 0.2578 - val_loss: 1.9666 - val_acc: 0.3392\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.28218 to 0.33915, saving model to /floyd/home/m6_t1.h5\n",
      "Epoch 3/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 2.1752 - acc: 0.2953 - val_loss: 2.5922 - val_acc: 0.4239\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.33915 to 0.42394, saving model to /floyd/home/m6_t1.h5\n",
      "Epoch 4/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 2.0961 - acc: 0.3300 - val_loss: 2.1492 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.42394\n",
      "Epoch 5/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.9991 - acc: 0.3516 - val_loss: 1.2973 - val_acc: 0.4875\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.42394 to 0.48753, saving model to /floyd/home/m6_t1.h5\n",
      "Epoch 6/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.9331 - acc: 0.3856 - val_loss: 1.2149 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.48753 to 0.51247, saving model to /floyd/home/m6_t1.h5\n",
      "Epoch 7/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.8529 - acc: 0.4098 - val_loss: 1.3579 - val_acc: 0.4489\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.51247\n",
      "Epoch 8/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.8269 - acc: 0.4207 - val_loss: 1.5919 - val_acc: 0.4738\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.51247\n",
      "Epoch 9/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.7696 - acc: 0.4369 - val_loss: 1.0412 - val_acc: 0.5249\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.51247 to 0.52494, saving model to /floyd/home/m6_t1.h5\n",
      "Epoch 10/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.7363 - acc: 0.4505 - val_loss: 1.6408 - val_acc: 0.5387\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.52494 to 0.53865, saving model to /floyd/home/m6_t1.h5\n",
      "Epoch 11/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.6957 - acc: 0.4684 - val_loss: 1.5052 - val_acc: 0.5162\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.53865\n",
      "Epoch 12/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.6536 - acc: 0.4770 - val_loss: 1.6862 - val_acc: 0.4988\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.53865\n",
      "Epoch 13/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.6083 - acc: 0.4886 - val_loss: 1.5350 - val_acc: 0.5648\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.53865 to 0.56484, saving model to /floyd/home/m6_t1.h5\n",
      "Epoch 14/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.5899 - acc: 0.4936 - val_loss: 1.0825 - val_acc: 0.5574\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.56484\n",
      "Epoch 15/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.5525 - acc: 0.4993 - val_loss: 0.7778 - val_acc: 0.5399\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.56484\n",
      "Epoch 16/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.5121 - acc: 0.5163 - val_loss: 1.2167 - val_acc: 0.5761\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.56484 to 0.57606, saving model to /floyd/home/m6_t1.h5\n",
      "Epoch 17/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.4934 - acc: 0.5260 - val_loss: 1.9171 - val_acc: 0.5711\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.57606\n",
      "Epoch 18/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.4592 - acc: 0.5442 - val_loss: 0.5857 - val_acc: 0.6234\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.57606 to 0.62344, saving model to /floyd/home/m6_t1.h5\n",
      "Epoch 19/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.4259 - acc: 0.5507 - val_loss: 1.1405 - val_acc: 0.5860\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.62344\n",
      "Epoch 20/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.4143 - acc: 0.5488 - val_loss: 1.2332 - val_acc: 0.6010\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.62344\n",
      "Epoch 21/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.3724 - acc: 0.5633 - val_loss: 1.3343 - val_acc: 0.6147\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.62344\n",
      "Epoch 22/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.3647 - acc: 0.5635 - val_loss: 2.3659 - val_acc: 0.6110\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.62344\n",
      "Epoch 23/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.3130 - acc: 0.5810 - val_loss: 1.0401 - val_acc: 0.6247\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.62344 to 0.62469, saving model to /floyd/home/m6_t1.h5\n",
      "Epoch 24/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.3299 - acc: 0.5794 - val_loss: 1.1893 - val_acc: 0.5885\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.62469\n",
      "Epoch 25/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.2931 - acc: 0.5821 - val_loss: 0.7516 - val_acc: 0.5810\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.62469\n",
      "Epoch 26/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.2703 - acc: 0.5975 - val_loss: 1.2669 - val_acc: 0.6596\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.62469 to 0.65960, saving model to /floyd/home/m6_t1.h5\n",
      "Epoch 27/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.2550 - acc: 0.6036 - val_loss: 0.7135 - val_acc: 0.6097\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.65960\n",
      "Epoch 28/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.2350 - acc: 0.6163 - val_loss: 0.8678 - val_acc: 0.6209\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.65960\n",
      "Epoch 29/30\n",
      "1013/1013 [==============================] - 75s 74ms/step - loss: 1.2083 - acc: 0.6158 - val_loss: 0.7494 - val_acc: 0.6509\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.65960\n",
      "Epoch 30/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.2091 - acc: 0.6189 - val_loss: 1.0884 - val_acc: 0.6234\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.65960\n",
      "CPU times: user 53min 18s, sys: 6min 8s, total: 59min 27s\n",
      "Wall time: 38min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m6_t1_cp = ModelCheckpoint(filepath=f'{model_path}m6_t1.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m6_t1_history = m6_t1.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m6_t1_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m6_t1_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 2.7505 - acc: 0.1386 - val_loss: 2.9185 - val_acc: 0.2153\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.21535, saving model to /floyd/home/m6_t2.h5\n",
      "Epoch 2/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 2.3673 - acc: 0.2264 - val_loss: 1.8793 - val_acc: 0.3092\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.21535 to 0.30923, saving model to /floyd/home/m6_t2.h5\n",
      "Epoch 3/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 2.2187 - acc: 0.2831 - val_loss: 1.8935 - val_acc: 0.3516\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.30923 to 0.35162, saving model to /floyd/home/m6_t2.h5\n",
      "Epoch 4/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 2.1186 - acc: 0.3216 - val_loss: 1.9212 - val_acc: 0.4302\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.35162 to 0.43017, saving model to /floyd/home/m6_t2.h5\n",
      "Epoch 5/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 2.0216 - acc: 0.3536 - val_loss: 1.7460 - val_acc: 0.4339\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.43017 to 0.43392, saving model to /floyd/home/m6_t2.h5\n",
      "Epoch 6/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.9356 - acc: 0.3741 - val_loss: 1.3708 - val_acc: 0.4825\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.43392 to 0.48254, saving model to /floyd/home/m6_t2.h5\n",
      "Epoch 7/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.8855 - acc: 0.4015 - val_loss: 1.0997 - val_acc: 0.4800\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.48254\n",
      "Epoch 8/30\n",
      "1013/1013 [==============================] - 75s 74ms/step - loss: 1.8227 - acc: 0.4258 - val_loss: 1.7412 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.48254 to 0.50000, saving model to /floyd/home/m6_t2.h5\n",
      "Epoch 9/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.7838 - acc: 0.4341 - val_loss: 1.5312 - val_acc: 0.4950\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.50000\n",
      "Epoch 10/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.7239 - acc: 0.4490 - val_loss: 1.6214 - val_acc: 0.4751\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.50000\n",
      "Epoch 11/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.6947 - acc: 0.4583 - val_loss: 1.9941 - val_acc: 0.5187\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.50000 to 0.51870, saving model to /floyd/home/m6_t2.h5\n",
      "Epoch 12/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.6172 - acc: 0.4875 - val_loss: 1.6251 - val_acc: 0.5511\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.51870 to 0.55112, saving model to /floyd/home/m6_t2.h5\n",
      "Epoch 13/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.6007 - acc: 0.4907 - val_loss: 1.6367 - val_acc: 0.5436\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.55112\n",
      "Epoch 14/30\n",
      "1013/1013 [==============================] - 75s 74ms/step - loss: 1.5708 - acc: 0.4981 - val_loss: 1.5721 - val_acc: 0.5324\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.55112\n",
      "Epoch 15/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.5459 - acc: 0.5121 - val_loss: 2.1472 - val_acc: 0.5299\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.55112\n",
      "Epoch 16/30\n",
      "1013/1013 [==============================] - 75s 74ms/step - loss: 1.5140 - acc: 0.5248 - val_loss: 1.3374 - val_acc: 0.6209\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.55112 to 0.62095, saving model to /floyd/home/m6_t2.h5\n",
      "Epoch 17/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.4840 - acc: 0.5314 - val_loss: 0.4331 - val_acc: 0.5873\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.62095\n",
      "Epoch 18/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.4658 - acc: 0.5305 - val_loss: 1.8750 - val_acc: 0.5599\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.62095\n",
      "Epoch 19/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.4264 - acc: 0.5501 - val_loss: 1.7285 - val_acc: 0.5960\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.62095\n",
      "Epoch 20/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.4129 - acc: 0.5474 - val_loss: 2.7438 - val_acc: 0.5337\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.62095\n",
      "Epoch 21/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.3816 - acc: 0.5552 - val_loss: 1.0579 - val_acc: 0.6247\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.62095 to 0.62469, saving model to /floyd/home/m6_t2.h5\n",
      "Epoch 22/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.3605 - acc: 0.5649 - val_loss: 0.8042 - val_acc: 0.6484\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.62469 to 0.64838, saving model to /floyd/home/m6_t2.h5\n",
      "Epoch 23/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.3585 - acc: 0.5670 - val_loss: 0.7826 - val_acc: 0.6621\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.64838 to 0.66209, saving model to /floyd/home/m6_t2.h5\n",
      "Epoch 24/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.3147 - acc: 0.5843 - val_loss: 0.9866 - val_acc: 0.6072\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.66209\n",
      "Epoch 25/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.2876 - acc: 0.5926 - val_loss: 1.5987 - val_acc: 0.6309\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.66209\n",
      "Epoch 26/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.2602 - acc: 0.5975 - val_loss: 1.2531 - val_acc: 0.6596\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.66209\n",
      "Epoch 27/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.2535 - acc: 0.5979 - val_loss: 0.6246 - val_acc: 0.6384\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.66209\n",
      "Epoch 28/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.2420 - acc: 0.6058 - val_loss: 0.5762 - val_acc: 0.6297\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.66209\n",
      "Epoch 29/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.1823 - acc: 0.6258 - val_loss: 1.0309 - val_acc: 0.6384\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.66209\n",
      "Epoch 30/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.1945 - acc: 0.6196 - val_loss: 0.8481 - val_acc: 0.6646\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.66209 to 0.66459, saving model to /floyd/home/m6_t2.h5\n",
      "CPU times: user 52min 56s, sys: 6min 7s, total: 59min 4s\n",
      "Wall time: 38min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m6_t2_cp = ModelCheckpoint(filepath=f'{model_path}m6_t2.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m6_t2_history = m6_t2.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m6_t2_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m6_t2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 2.9541 - acc: 0.1677 - val_loss: 2.9807 - val_acc: 0.2723\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.27228, saving model to /floyd/home/m6_t3.h5\n",
      "Epoch 2/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 2.3421 - acc: 0.2572 - val_loss: 2.1329 - val_acc: 0.3566\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.27228 to 0.35661, saving model to /floyd/home/m6_t3.h5\n",
      "Epoch 3/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 2.2194 - acc: 0.2860 - val_loss: 2.4192 - val_acc: 0.3666\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.35661 to 0.36658, saving model to /floyd/home/m6_t3.h5\n",
      "Epoch 4/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 2.1033 - acc: 0.3270 - val_loss: 1.7728 - val_acc: 0.4501\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.36658 to 0.45012, saving model to /floyd/home/m6_t3.h5\n",
      "Epoch 5/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 2.0029 - acc: 0.3616 - val_loss: 1.8867 - val_acc: 0.4489\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.45012\n",
      "Epoch 6/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.9231 - acc: 0.3848 - val_loss: 2.3081 - val_acc: 0.4713\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.45012 to 0.47132, saving model to /floyd/home/m6_t3.h5\n",
      "Epoch 7/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.8573 - acc: 0.4117 - val_loss: 1.4678 - val_acc: 0.4751\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.47132 to 0.47506, saving model to /floyd/home/m6_t3.h5\n",
      "Epoch 8/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.8095 - acc: 0.4244 - val_loss: 1.2634 - val_acc: 0.4688\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.47506\n",
      "Epoch 9/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.7349 - acc: 0.4494 - val_loss: 0.8570 - val_acc: 0.5349\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.47506 to 0.53491, saving model to /floyd/home/m6_t3.h5\n",
      "Epoch 10/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.6977 - acc: 0.4542 - val_loss: 1.2531 - val_acc: 0.5511\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.53491 to 0.55112, saving model to /floyd/home/m6_t3.h5\n",
      "Epoch 11/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.6527 - acc: 0.4785 - val_loss: 1.1586 - val_acc: 0.4938\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.55112\n",
      "Epoch 12/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.6153 - acc: 0.4944 - val_loss: 1.5127 - val_acc: 0.5287\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.55112\n",
      "Epoch 13/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.5806 - acc: 0.4962 - val_loss: 1.0453 - val_acc: 0.5835\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.55112 to 0.58354, saving model to /floyd/home/m6_t3.h5\n",
      "Epoch 14/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.5577 - acc: 0.5051 - val_loss: 0.5549 - val_acc: 0.5561\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.58354\n",
      "Epoch 15/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.5283 - acc: 0.5154 - val_loss: 1.6895 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.58354\n",
      "Epoch 16/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.4770 - acc: 0.5373 - val_loss: 1.4672 - val_acc: 0.5998\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.58354 to 0.59975, saving model to /floyd/home/m6_t3.h5\n",
      "Epoch 17/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.4585 - acc: 0.5362 - val_loss: 1.0987 - val_acc: 0.5885\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.59975\n",
      "Epoch 18/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.4165 - acc: 0.5544 - val_loss: 0.9250 - val_acc: 0.6097\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.59975 to 0.60973, saving model to /floyd/home/m6_t3.h5\n",
      "Epoch 19/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.3962 - acc: 0.5528 - val_loss: 1.4004 - val_acc: 0.6072\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.60973\n",
      "Epoch 20/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.3541 - acc: 0.5701 - val_loss: 0.8967 - val_acc: 0.5773\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.60973\n",
      "Epoch 21/30\n",
      "1013/1013 [==============================] - 75s 74ms/step - loss: 1.3664 - acc: 0.5717 - val_loss: 1.6981 - val_acc: 0.6272\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.60973 to 0.62718, saving model to /floyd/home/m6_t3.h5\n",
      "Epoch 22/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.3387 - acc: 0.5759 - val_loss: 0.5856 - val_acc: 0.6234\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.62718\n",
      "Epoch 23/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.3076 - acc: 0.5921 - val_loss: 0.6289 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.62718 to 0.64963, saving model to /floyd/home/m6_t3.h5\n",
      "Epoch 24/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.2795 - acc: 0.5948 - val_loss: 0.6141 - val_acc: 0.6459\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.64963\n",
      "Epoch 25/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.2616 - acc: 0.6016 - val_loss: 1.0728 - val_acc: 0.5561\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.64963\n",
      "Epoch 26/30\n",
      "1013/1013 [==============================] - 75s 74ms/step - loss: 1.2494 - acc: 0.6099 - val_loss: 1.6296 - val_acc: 0.6222\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.64963\n",
      "Epoch 27/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.2268 - acc: 0.6163 - val_loss: 0.5074 - val_acc: 0.6097\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.64963\n",
      "Epoch 28/30\n",
      "1013/1013 [==============================] - 75s 74ms/step - loss: 1.1938 - acc: 0.6222 - val_loss: 1.1985 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.64963\n",
      "Epoch 29/30\n",
      "1013/1013 [==============================] - 75s 74ms/step - loss: 1.2000 - acc: 0.6231 - val_loss: 1.0994 - val_acc: 0.5786\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.64963\n",
      "Epoch 30/30\n",
      "1013/1013 [==============================] - 75s 74ms/step - loss: 1.1700 - acc: 0.6299 - val_loss: 1.4247 - val_acc: 0.6047\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.64963\n",
      "CPU times: user 53min 1s, sys: 6min 8s, total: 59min 10s\n",
      "Wall time: 38min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m6_t3_cp = ModelCheckpoint(filepath=f'{model_path}m6_t3.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m6_t3_history = m6_t3.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m6_t3_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m6_t3_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 2.9465 - acc: 0.1719 - val_loss: 2.0469 - val_acc: 0.2995\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.29950, saving model to /floyd/home/m6_t4.h5\n",
      "Epoch 2/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 2.3500 - acc: 0.2557 - val_loss: 1.6644 - val_acc: 0.3229\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.29950 to 0.32294, saving model to /floyd/home/m6_t4.h5\n",
      "Epoch 3/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 2.2191 - acc: 0.2881 - val_loss: 1.2348 - val_acc: 0.3429\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.32294 to 0.34289, saving model to /floyd/home/m6_t4.h5\n",
      "Epoch 4/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 2.0843 - acc: 0.3346 - val_loss: 2.6100 - val_acc: 0.3953\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.34289 to 0.39526, saving model to /floyd/home/m6_t4.h5\n",
      "Epoch 5/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 2.0163 - acc: 0.3591 - val_loss: 2.0516 - val_acc: 0.4526\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.39526 to 0.45262, saving model to /floyd/home/m6_t4.h5\n",
      "Epoch 6/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.9288 - acc: 0.3820 - val_loss: 2.2124 - val_acc: 0.4676\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.45262 to 0.46758, saving model to /floyd/home/m6_t4.h5\n",
      "Epoch 7/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.8710 - acc: 0.4088 - val_loss: 1.4783 - val_acc: 0.4913\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.46758 to 0.49127, saving model to /floyd/home/m6_t4.h5\n",
      "Epoch 8/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.8208 - acc: 0.4256 - val_loss: 1.0768 - val_acc: 0.4863\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.49127\n",
      "Epoch 9/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.7682 - acc: 0.4367 - val_loss: 1.0089 - val_acc: 0.4863\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.49127\n",
      "Epoch 10/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.7058 - acc: 0.4516 - val_loss: 1.8436 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.49127 to 0.51247, saving model to /floyd/home/m6_t4.h5\n",
      "Epoch 11/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.6839 - acc: 0.4628 - val_loss: 2.3732 - val_acc: 0.4601\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.51247\n",
      "Epoch 12/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.6330 - acc: 0.4783 - val_loss: 1.8400 - val_acc: 0.5224\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.51247 to 0.52244, saving model to /floyd/home/m6_t4.h5\n",
      "Epoch 13/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.6076 - acc: 0.4957 - val_loss: 2.1440 - val_acc: 0.5287\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.52244 to 0.52868, saving model to /floyd/home/m6_t4.h5\n",
      "Epoch 14/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.5600 - acc: 0.5096 - val_loss: 0.9978 - val_acc: 0.5511\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.52868 to 0.55112, saving model to /floyd/home/m6_t4.h5\n",
      "Epoch 15/30\n",
      "1013/1013 [==============================] - 75s 75ms/step - loss: 1.5300 - acc: 0.5193 - val_loss: 1.7040 - val_acc: 0.6222\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.55112 to 0.62219, saving model to /floyd/home/m6_t4.h5\n",
      "Epoch 16/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.4960 - acc: 0.5260 - val_loss: 1.1368 - val_acc: 0.5025\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.62219\n",
      "Epoch 17/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.4688 - acc: 0.5369 - val_loss: 1.5455 - val_acc: 0.5574\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.62219\n",
      "Epoch 18/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.4349 - acc: 0.5432 - val_loss: 2.0361 - val_acc: 0.5761\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.62219\n",
      "Epoch 19/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.4255 - acc: 0.5443 - val_loss: 1.2144 - val_acc: 0.5935\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.62219\n",
      "Epoch 20/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.4114 - acc: 0.5509 - val_loss: 1.7353 - val_acc: 0.5960\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.62219\n",
      "Epoch 21/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.3660 - acc: 0.5648 - val_loss: 2.4577 - val_acc: 0.5998\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.62219\n",
      "Epoch 22/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.3569 - acc: 0.5748 - val_loss: 1.0595 - val_acc: 0.5798\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.62219\n",
      "Epoch 23/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.3433 - acc: 0.5846 - val_loss: 1.1161 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.62219 to 0.64963, saving model to /floyd/home/m6_t4.h5\n",
      "Epoch 24/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.3175 - acc: 0.5838 - val_loss: 1.3411 - val_acc: 0.5786\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.64963\n",
      "Epoch 25/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.2893 - acc: 0.5923 - val_loss: 0.8508 - val_acc: 0.6359\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.64963\n",
      "Epoch 26/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.2680 - acc: 0.6015 - val_loss: 2.6457 - val_acc: 0.6384\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.64963\n",
      "Epoch 27/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.2438 - acc: 0.6106 - val_loss: 1.2376 - val_acc: 0.6110\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.64963\n",
      "Epoch 28/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.2427 - acc: 0.6084 - val_loss: 0.9293 - val_acc: 0.6284\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.64963\n",
      "Epoch 29/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.2425 - acc: 0.6044 - val_loss: 1.1389 - val_acc: 0.5773\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.64963\n",
      "Epoch 30/30\n",
      "1013/1013 [==============================] - 76s 75ms/step - loss: 1.2136 - acc: 0.6195 - val_loss: 1.2597 - val_acc: 0.5985\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.64963\n",
      "CPU times: user 53min 17s, sys: 6min 8s, total: 59min 25s\n",
      "Wall time: 38min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m6_t4_cp = ModelCheckpoint(filepath=f'{model_path}m6_t4.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m6_t4_history = m6_t4.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m6_t4_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m6_t4_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary for model names, models, and histories from respective lists\n",
    "models_dict = {i:[j,k] for i,j,k in zip(model_names,model_list,model_hists)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 2s 17ms/step\n",
      "m6_t1 Val Accuracy: 64.57%\n",
      "m6_t1 Val Loss: 1.0852\n",
      "---\n",
      "102/102 [==============================] - 2s 17ms/step\n",
      "m6_t2 Val Accuracy: 66.67%\n",
      "m6_t2 Val Loss: 2.523\n",
      "---\n",
      "102/102 [==============================] - 2s 17ms/step\n",
      "m6_t3 Val Accuracy: 63.46%\n",
      "m6_t3 Val Loss: 1.7824\n",
      "---\n",
      "102/102 [==============================] - 2s 17ms/step\n",
      "m6_t4 Val Accuracy: 65.31%\n",
      "m6_t4 Val Loss: 1.911\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# evaluating models on validation set\n",
    "for key, value in models_dict.items():\n",
    "    model = models.load_model(f'{model_path}{key}.h5')\n",
    "    (val_loss, val_accuracy) = model.evaluate(val_generator,verbose=1)\n",
    "    print(f'{key} Val Accuracy: {round((val_accuracy*100),2)}%')\n",
    "    print(f'{key} Val Loss: {round(val_loss,4)}')\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m6_t1_history saved in /floyd/home/\n",
      "m6_t2_history saved in /floyd/home/\n",
      "m6_t3_history saved in /floyd/home/\n",
      "m6_t4_history saved in /floyd/home/\n"
     ]
    }
   ],
   "source": [
    "# saving training histories\n",
    "for key, value in models_dict.items():\n",
    "    with open(f'{model_path}{key}_history', 'wb') as file_pi:\n",
    "        pickle.dump(value[1].history, file_pi)\n",
    "    print(f'{key}_history saved in {model_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
