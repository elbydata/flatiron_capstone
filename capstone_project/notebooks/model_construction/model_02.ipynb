{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the construction and training of the model iterations and various experiments. The notebook is split up into four sections: training mode selection (where the model will run), set-up, model constrution, and training. \n",
    "\n",
    "Evaluation will take place in the *model_optimization_and_evaluation.ipynb* notebook found in the *notebooks* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import applications \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Training Mode Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, specify the training mode for the model. This will determine the location from which the source data is drawn, and to which the trained models (and training histories) are saved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **training_mode = 'floydhub'** (runs on Floydhub)\n",
    "- **training_mode = 'local'** (runs on local disk and processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select training mode\n",
    "training_mode = 'floydhub'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory base paths\n",
    "data_path_local = '../../data/0002_array_data/train_data/'\n",
    "model_path_local = '../../notebooks/model_construction/saved_models/'\n",
    "data_path_floydhub = '/floyd/input/capstone_mushrooms/'\n",
    "model_path_floydhub = '/floyd/home/'\n",
    "\n",
    "# setting directory paths based on training mode selection\n",
    "if training_mode == 'floydhub':\n",
    "    data_path = data_path_floydhub\n",
    "    model_path = model_path_floydhub\n",
    "elif training_mode == 'local':\n",
    "    data_path = data_path_local\n",
    "    model_path = model_path_local\n",
    "else:\n",
    "    raise Exception('Please choose valid training mode: \"floydhub\" or \"local\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the training and validation data subsets\n",
    "X_train = np.load(f'{data_path}X_train_data.npy')\n",
    "y_train = np.load(f'{data_path}y_train_data.npy')\n",
    "X_val = np.load(f'{data_path}X_val_data.npy')\n",
    "y_val = np.load(f'{data_path}y_val_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting training parameters\n",
    "batch_size = 32\n",
    "n_classes = 20\n",
    "n_epochs = 15\n",
    "img_shape = X_train.shape[1:]\n",
    "model_names = []\n",
    "model_list = []\n",
    "model_hists = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 1 - Single convolution layer and dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "model_02 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "model_02.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=img_shape, padding='same'))\n",
    "model_02.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model_02.add(layers.Conv2D(64,(3,3), activation='relu', padding='same'))\n",
    "model_02.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model_02.add(layers.Conv2D(128,(3,3), activation='relu', padding='same'))\n",
    "model_02.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model_02.add(layers.Conv2D(256,(3,3), activation='relu', padding='same'))\n",
    "model_02.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "model_02.add(layers.Flatten())\n",
    "model_02.add(layers.Dense(512, activation='relu'))\n",
    "model_02.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "model_02.summary()\n",
    "model_names.append('model_02')\n",
    "model_list.append(model_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up standardization and augmentation parameters\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.3,\n",
    "                                   height_shift_range=0.3,\n",
    "                                   shear_range=0.3,\n",
    "                                   zoom_range=0.3,\n",
    "                                   fill_mode='nearest',\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 341 ms, sys: 936 ms, total: 1.28 s\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data standardization and augmentation\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling loss functions\n",
    "model_02.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "253/253 [==============================] - 136s 537ms/step - loss: 2.8623 - acc: 0.1026 - val_loss: 2.5536 - val_acc: 0.1750\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.17500, saving model to /floyd/home/model_02.h5\n",
      "Epoch 2/15\n",
      "253/253 [==============================] - 71s 282ms/step - loss: 2.4822 - acc: 0.2011 - val_loss: 2.6131 - val_acc: 0.2635\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.17500 to 0.26350, saving model to /floyd/home/model_02.h5\n",
      "Epoch 3/15\n",
      "253/253 [==============================] - 71s 282ms/step - loss: 2.3062 - acc: 0.2488 - val_loss: 2.1474 - val_acc: 0.3072\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.26350 to 0.30720, saving model to /floyd/home/model_02.h5\n",
      "Epoch 4/15\n",
      "253/253 [==============================] - 71s 280ms/step - loss: 2.2130 - acc: 0.2784 - val_loss: 1.7737 - val_acc: 0.3483\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.30720 to 0.34833, saving model to /floyd/home/model_02.h5\n",
      "Epoch 5/15\n",
      "253/253 [==============================] - 71s 279ms/step - loss: 2.1373 - acc: 0.3034 - val_loss: 2.1039 - val_acc: 0.3766\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.34833 to 0.37661, saving model to /floyd/home/model_02.h5\n",
      "Epoch 6/15\n",
      "253/253 [==============================] - 71s 280ms/step - loss: 2.0447 - acc: 0.3403 - val_loss: 2.2581 - val_acc: 0.4010\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.37661 to 0.40103, saving model to /floyd/home/model_02.h5\n",
      "Epoch 7/15\n",
      "253/253 [==============================] - 70s 278ms/step - loss: 1.9973 - acc: 0.3525 - val_loss: 1.5887 - val_acc: 0.4473\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.40103 to 0.44730, saving model to /floyd/home/model_02.h5\n",
      "Epoch 8/15\n",
      "253/253 [==============================] - 70s 279ms/step - loss: 1.9603 - acc: 0.3749 - val_loss: 1.3372 - val_acc: 0.4075\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.44730\n",
      "Epoch 9/15\n",
      "253/253 [==============================] - 70s 277ms/step - loss: 1.9101 - acc: 0.3874 - val_loss: 1.5339 - val_acc: 0.4409\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.44730\n",
      "Epoch 10/15\n",
      "253/253 [==============================] - 70s 277ms/step - loss: 1.8472 - acc: 0.4084 - val_loss: 1.4657 - val_acc: 0.4640\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.44730 to 0.46401, saving model to /floyd/home/model_02.h5\n",
      "Epoch 11/15\n",
      "253/253 [==============================] - 70s 277ms/step - loss: 1.8153 - acc: 0.4113 - val_loss: 1.4026 - val_acc: 0.4769\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.46401 to 0.47686, saving model to /floyd/home/model_02.h5\n",
      "Epoch 12/15\n",
      "253/253 [==============================] - 70s 278ms/step - loss: 1.7647 - acc: 0.4366 - val_loss: 1.5562 - val_acc: 0.4974\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.47686 to 0.49743, saving model to /floyd/home/model_02.h5\n",
      "Epoch 13/15\n",
      "253/253 [==============================] - 71s 279ms/step - loss: 1.7399 - acc: 0.4428 - val_loss: 1.4093 - val_acc: 0.4923\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.49743\n",
      "Epoch 14/15\n",
      "253/253 [==============================] - 71s 279ms/step - loss: 1.7524 - acc: 0.4416 - val_loss: 1.6587 - val_acc: 0.4679\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.49743\n",
      "Epoch 15/15\n",
      "253/253 [==============================] - 70s 276ms/step - loss: 1.6868 - acc: 0.4497 - val_loss: 2.0400 - val_acc: 0.4692\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.49743\n",
      "CPU times: user 21min 34s, sys: 1min 43s, total: 23min 17s\n",
      "Wall time: 19min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "model_02_cp = ModelCheckpoint(filepath=f'{model_path}model_02.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "model_02_history = model_02.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[model_02_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(model_02_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary for model names, models, and histories from respective lists\n",
    "models_dict = {i:[j,k] for i,j,k in zip(model_names,model_list,model_hists)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 42ms/step\n",
      "model_02 Val Accuracy: 47.78%\n",
      "model_02 Val Loss: 2.2701\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# evaluating models on validation set\n",
    "for key, value in models_dict.items():\n",
    "    model = models.load_model(f'{model_path}{key}.h5')\n",
    "    (val_loss, val_accuracy) = model.evaluate(val_generator,verbose=1)\n",
    "    print(f'{key} Val Accuracy: {round((val_accuracy*100),2)}%')\n",
    "    print(f'{key} Val Loss: {round(val_loss,4)}')\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_02_history saved in /floyd/home/\n"
     ]
    }
   ],
   "source": [
    "# saving training histories\n",
    "for key, value in models_dict.items():\n",
    "    with open(f'{model_path}{key}_history', 'wb') as file_pi:\n",
    "        pickle.dump(value[1].history, file_pi)\n",
    "    print(f'{key}_history saved in {model_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
