{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 9: Learning Rate Sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the construction and training of the model iterations and various experiments. The notebook is split up into four sections: training mode selection (where the model will run), set-up, model constrution, and training. \n",
    "\n",
    "Evaluation will take place in the *model_optimization_and_evaluation.ipynb* notebook found in the *notebooks* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import applications \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Training Mode Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, specify the training mode for the model. This will determine the location from which the source data is drawn, and to which the trained models (and training histories) are saved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **training_mode = 'floydhub'** (runs on Floydhub)\n",
    "- **training_mode = 'local'** (runs on local disk and processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select training mode\n",
    "training_mode = 'floydhub'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory base paths\n",
    "data_path_local = '../../data/0002_array_data/train_data/'\n",
    "model_path_local = '../../notebooks/model_construction/saved_models/'\n",
    "data_path_floydhub = '/floyd/input/capstone_mushrooms/'\n",
    "model_path_floydhub = '/floyd/home/'\n",
    "\n",
    "# setting directory paths based on training mode selection\n",
    "if training_mode == 'floydhub':\n",
    "    data_path = data_path_floydhub\n",
    "    model_path = model_path_floydhub\n",
    "elif training_mode == 'local':\n",
    "    data_path = data_path_local\n",
    "    model_path = model_path_local\n",
    "else:\n",
    "    raise Exception('Please choose valid training mode: \"floydhub\" or \"local\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the training and validation data subsets\n",
    "X_train = np.load(f'{data_path}X_train_data.npy')\n",
    "y_train = np.load(f'{data_path}y_train_data.npy')\n",
    "X_val = np.load(f'{data_path}X_val_data.npy')\n",
    "y_val = np.load(f'{data_path}y_val_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting training parameters\n",
    "batch_size = 8\n",
    "n_classes = 20\n",
    "n_epochs = 30\n",
    "img_shape = X_train.shape[1:]\n",
    "model_names = []\n",
    "model_list = []\n",
    "model_hists = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                20500     \n",
      "=================================================================\n",
      "Total params: 20,464,468\n",
      "Trainable params: 20,464,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m9_t1 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m9_t1.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same'))\n",
    "m9_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t1.add(layers.Conv2D(64,(3,3), padding='same'))\n",
    "m9_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t1.add(layers.Conv2D(128,(3,3), padding='same'))\n",
    "m9_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t1.add(layers.Conv2D(256,(3,3), padding='same'))\n",
    "m9_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t1.add(layers.Conv2D(512,(3,3), padding='same'))\n",
    "m9_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m9_t1.add(layers.Flatten())\n",
    "m9_t1.add(layers.Dense(1024))\n",
    "m9_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t1.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m9_t1.summary()\n",
    "model_names.append('m9_t1')\n",
    "model_list.append(m9_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                20500     \n",
      "=================================================================\n",
      "Total params: 20,464,468\n",
      "Trainable params: 20,464,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m9_t2 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m9_t2.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same'))\n",
    "m9_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t2.add(layers.Conv2D(64,(3,3), padding='same'))\n",
    "m9_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t2.add(layers.Conv2D(128,(3,3), padding='same'))\n",
    "m9_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t2.add(layers.Conv2D(256,(3,3), padding='same'))\n",
    "m9_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t2.add(layers.Conv2D(512,(3,3), padding='same'))\n",
    "m9_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m9_t2.add(layers.Flatten())\n",
    "m9_t2.add(layers.Dense(1024))\n",
    "m9_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t2.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m9_t2.summary()\n",
    "model_names.append('m9_t2')\n",
    "model_list.append(m9_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20)                20500     \n",
      "=================================================================\n",
      "Total params: 20,464,468\n",
      "Trainable params: 20,464,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m9_t3 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m9_t3.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same'))\n",
    "m9_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t3.add(layers.Conv2D(64,(3,3), padding='same'))\n",
    "m9_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t3.add(layers.Conv2D(128,(3,3), padding='same'))\n",
    "m9_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t3.add(layers.Conv2D(256,(3,3), padding='same'))\n",
    "m9_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t3.add(layers.Conv2D(512,(3,3), padding='same'))\n",
    "m9_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m9_t3.add(layers.Flatten())\n",
    "m9_t3.add(layers.Dense(1024))\n",
    "m9_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t3.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m9_t3.summary()\n",
    "model_names.append('m9_t3')\n",
    "model_list.append(m9_t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                20500     \n",
      "=================================================================\n",
      "Total params: 20,464,468\n",
      "Trainable params: 20,464,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m9_t4 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m9_t4.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same'))\n",
    "m9_t4.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t4.add(layers.Conv2D(64,(3,3), padding='same'))\n",
    "m9_t4.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t4.add(layers.Conv2D(128,(3,3), padding='same'))\n",
    "m9_t4.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t4.add(layers.Conv2D(256,(3,3), padding='same'))\n",
    "m9_t4.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t4.add(layers.Conv2D(512,(3,3), padding='same'))\n",
    "m9_t4.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m9_t4.add(layers.Flatten())\n",
    "m9_t4.add(layers.Dense(1024))\n",
    "m9_t4.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t4.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m9_t4.summary()\n",
    "model_names.append('m9_t4')\n",
    "model_list.append(m9_t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 20)                20500     \n",
      "=================================================================\n",
      "Total params: 20,464,468\n",
      "Trainable params: 20,464,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m9_t5 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m9_t5.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same'))\n",
    "m9_t5.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t5.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t5.add(layers.Conv2D(64,(3,3), padding='same'))\n",
    "m9_t5.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t5.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t5.add(layers.Conv2D(128,(3,3), padding='same'))\n",
    "m9_t5.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t5.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t5.add(layers.Conv2D(256,(3,3), padding='same'))\n",
    "m9_t5.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t5.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m9_t5.add(layers.Conv2D(512,(3,3), padding='same'))\n",
    "m9_t5.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t5.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m9_t5.add(layers.Flatten())\n",
    "m9_t5.add(layers.Dense(1024))\n",
    "m9_t5.add(layers.LeakyReLU(alpha=0.1))\n",
    "m9_t5.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m9_t5.summary()\n",
    "model_names.append('m9_t5')\n",
    "model_list.append(m9_t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up standardization and augmentation parameters\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.3,\n",
    "                                   height_shift_range=0.3,\n",
    "                                   shear_range=0.3,\n",
    "                                   zoom_range=0.3,\n",
    "                                   fill_mode='nearest',\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 326 ms, sys: 1.4 s, total: 1.72 s\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data standardization and augmentation\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up optimizer\n",
    "opt_1 = optimizers.Adamax(learning_rate=9e-4)\n",
    "opt_2 = optimizers.Adamax(learning_rate=7e-4)\n",
    "opt_3 = optimizers.Adamax(learning_rate=5e-4)\n",
    "opt_4 = optimizers.Adamax(learning_rate=3e-4)\n",
    "opt_5 = optimizers.Adamax(learning_rate=1e-4)\n",
    "\n",
    "# compiling loss functions\n",
    "m9_t1.compile(loss='categorical_crossentropy', optimizer=opt_1, metrics=['acc'])\n",
    "m9_t2.compile(loss='categorical_crossentropy', optimizer=opt_2, metrics=['acc'])\n",
    "m9_t3.compile(loss='categorical_crossentropy', optimizer=opt_3, metrics=['acc'])\n",
    "m9_t4.compile(loss='categorical_crossentropy', optimizer=opt_4, metrics=['acc'])\n",
    "m9_t5.compile(loss='categorical_crossentropy', optimizer=opt_5, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1013/1013 [==============================] - 155s 153ms/step - loss: 2.6631 - acc: 0.1504 - val_loss: 1.7678 - val_acc: 0.2475\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.24752, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 2/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.2922 - acc: 0.2596 - val_loss: 1.6604 - val_acc: 0.3603\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.24752 to 0.36035, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 3/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.1510 - acc: 0.3065 - val_loss: 2.4284 - val_acc: 0.4127\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.36035 to 0.41272, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 4/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.0256 - acc: 0.3479 - val_loss: 1.9253 - val_acc: 0.4227\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.41272 to 0.42269, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 5/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.9194 - acc: 0.3835 - val_loss: 2.1385 - val_acc: 0.4726\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.42269 to 0.47257, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 6/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.8386 - acc: 0.4128 - val_loss: 1.4772 - val_acc: 0.4825\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.47257 to 0.48254, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 7/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.7805 - acc: 0.4335 - val_loss: 1.0637 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.48254 to 0.51247, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 8/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.7100 - acc: 0.4544 - val_loss: 1.3949 - val_acc: 0.5150\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.51247 to 0.51496, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 9/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6410 - acc: 0.4695 - val_loss: 0.9254 - val_acc: 0.5636\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.51496 to 0.56359, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 10/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6137 - acc: 0.4796 - val_loss: 1.5338 - val_acc: 0.5449\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.56359\n",
      "Epoch 11/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.5219 - acc: 0.5136 - val_loss: 1.3738 - val_acc: 0.5424\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.56359\n",
      "Epoch 12/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.4893 - acc: 0.5267 - val_loss: 0.5593 - val_acc: 0.5923\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.56359 to 0.59227, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 13/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.4395 - acc: 0.5342 - val_loss: 1.3203 - val_acc: 0.5786\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.59227\n",
      "Epoch 14/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.3854 - acc: 0.5505 - val_loss: 0.9194 - val_acc: 0.6085\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.59227 to 0.60848, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 15/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.3636 - acc: 0.5600 - val_loss: 0.4635 - val_acc: 0.6384\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.60848 to 0.63840, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 16/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.3085 - acc: 0.5831 - val_loss: 1.7852 - val_acc: 0.6209\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.63840\n",
      "Epoch 17/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.2714 - acc: 0.5935 - val_loss: 1.0583 - val_acc: 0.6085\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.63840\n",
      "Epoch 18/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.2137 - acc: 0.6085 - val_loss: 1.8229 - val_acc: 0.5773\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.63840\n",
      "Epoch 19/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.1888 - acc: 0.6238 - val_loss: 0.6436 - val_acc: 0.6696\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.63840 to 0.66958, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 20/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.1601 - acc: 0.6333 - val_loss: 0.8902 - val_acc: 0.6521\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.66958\n",
      "Epoch 21/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.1378 - acc: 0.6269 - val_loss: 0.3532 - val_acc: 0.6783\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.66958 to 0.67830, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 22/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.1070 - acc: 0.6437 - val_loss: 0.5578 - val_acc: 0.6633\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.67830\n",
      "Epoch 23/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.0662 - acc: 0.6601 - val_loss: 2.0052 - val_acc: 0.6671\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.67830\n",
      "Epoch 24/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.0510 - acc: 0.6664 - val_loss: 0.4064 - val_acc: 0.7057\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.67830 to 0.70574, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 25/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.0468 - acc: 0.6625 - val_loss: 0.2322 - val_acc: 0.7032\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.70574\n",
      "Epoch 26/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 0.9975 - acc: 0.6772 - val_loss: 1.2721 - val_acc: 0.6958\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.70574\n",
      "Epoch 27/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 0.9770 - acc: 0.6872 - val_loss: 0.7115 - val_acc: 0.6459\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.70574\n",
      "Epoch 28/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 0.9459 - acc: 0.6957 - val_loss: 0.4655 - val_acc: 0.7232\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.70574 to 0.72319, saving model to /floyd/home/m9_t1.h5\n",
      "Epoch 29/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 0.9417 - acc: 0.6935 - val_loss: 0.7882 - val_acc: 0.6509\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.72319\n",
      "Epoch 30/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 0.9161 - acc: 0.7054 - val_loss: 0.7341 - val_acc: 0.7057\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.72319\n",
      "CPU times: user 56min 23s, sys: 6min 56s, total: 1h 3min 20s\n",
      "Wall time: 40min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m9_t1_cp = ModelCheckpoint(filepath=f'{model_path}m9_t1.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m9_t1_history = m9_t1.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m9_t1_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m9_t1_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.6328 - acc: 0.1648 - val_loss: 2.5249 - val_acc: 0.2636\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.26361, saving model to /floyd/home/m9_t2.h5\n",
      "Epoch 2/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.2642 - acc: 0.2662 - val_loss: 1.8648 - val_acc: 0.3653\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.26361 to 0.36534, saving model to /floyd/home/m9_t2.h5\n",
      "Epoch 3/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.1072 - acc: 0.3194 - val_loss: 1.7667 - val_acc: 0.4015\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.36534 to 0.40150, saving model to /floyd/home/m9_t2.h5\n",
      "Epoch 4/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.0044 - acc: 0.3574 - val_loss: 0.8099 - val_acc: 0.4701\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.40150 to 0.47007, saving model to /floyd/home/m9_t2.h5\n",
      "Epoch 5/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.8959 - acc: 0.3943 - val_loss: 1.4832 - val_acc: 0.4663\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.47007\n",
      "Epoch 6/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.8207 - acc: 0.4200 - val_loss: 1.8652 - val_acc: 0.4676\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.47007\n",
      "Epoch 7/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.7567 - acc: 0.4390 - val_loss: 1.5708 - val_acc: 0.5287\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.47007 to 0.52868, saving model to /floyd/home/m9_t2.h5\n",
      "Epoch 8/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6784 - acc: 0.4685 - val_loss: 1.2685 - val_acc: 0.5499\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.52868 to 0.54988, saving model to /floyd/home/m9_t2.h5\n",
      "Epoch 9/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6307 - acc: 0.4840 - val_loss: 1.4643 - val_acc: 0.5623\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.54988 to 0.56234, saving model to /floyd/home/m9_t2.h5\n",
      "Epoch 10/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.5762 - acc: 0.4975 - val_loss: 1.3226 - val_acc: 0.5698\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.56234 to 0.56983, saving model to /floyd/home/m9_t2.h5\n",
      "Epoch 11/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.5184 - acc: 0.5069 - val_loss: 0.2097 - val_acc: 0.6122\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.56983 to 0.61222, saving model to /floyd/home/m9_t2.h5\n",
      "Epoch 12/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.4801 - acc: 0.5207 - val_loss: 1.1109 - val_acc: 0.6197\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.61222 to 0.61970, saving model to /floyd/home/m9_t2.h5\n",
      "Epoch 13/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.4373 - acc: 0.5381 - val_loss: 1.2325 - val_acc: 0.5910\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.61970\n",
      "Epoch 14/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.3880 - acc: 0.5553 - val_loss: 2.3087 - val_acc: 0.6122\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.61970\n",
      "Epoch 15/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.3638 - acc: 0.5654 - val_loss: 1.6262 - val_acc: 0.5835\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.61970\n",
      "Epoch 16/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.3160 - acc: 0.5757 - val_loss: 1.6375 - val_acc: 0.5985\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.61970\n",
      "Epoch 17/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.2742 - acc: 0.5877 - val_loss: 0.8752 - val_acc: 0.6309\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.61970 to 0.63092, saving model to /floyd/home/m9_t2.h5\n",
      "Epoch 18/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.2601 - acc: 0.5973 - val_loss: 1.2727 - val_acc: 0.6047\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.63092\n",
      "Epoch 19/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.2215 - acc: 0.6004 - val_loss: 1.9022 - val_acc: 0.5923\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.63092\n",
      "Epoch 20/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.1839 - acc: 0.6170 - val_loss: 0.9588 - val_acc: 0.6085\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.63092\n",
      "Epoch 21/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.1488 - acc: 0.6296 - val_loss: 0.7014 - val_acc: 0.6471\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.63092 to 0.64713, saving model to /floyd/home/m9_t2.h5\n",
      "Epoch 22/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.1207 - acc: 0.6399 - val_loss: 1.5818 - val_acc: 0.6259\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.64713\n",
      "Epoch 23/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.0941 - acc: 0.6464 - val_loss: 1.6255 - val_acc: 0.6010\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.64713\n",
      "Epoch 24/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.0741 - acc: 0.6542 - val_loss: 1.2342 - val_acc: 0.6409\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.64713\n",
      "Epoch 25/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.0492 - acc: 0.6644 - val_loss: 1.4867 - val_acc: 0.6658\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.64713 to 0.66584, saving model to /floyd/home/m9_t2.h5\n",
      "Epoch 26/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.0253 - acc: 0.6737 - val_loss: 0.8011 - val_acc: 0.6359\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.66584\n",
      "Epoch 27/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.0104 - acc: 0.6723 - val_loss: 0.4260 - val_acc: 0.6746\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.66584 to 0.67456, saving model to /floyd/home/m9_t2.h5\n",
      "Epoch 28/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 0.9764 - acc: 0.6806 - val_loss: 0.2864 - val_acc: 0.6347\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.67456\n",
      "Epoch 29/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 0.9668 - acc: 0.6895 - val_loss: 0.5027 - val_acc: 0.6895\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.67456 to 0.68953, saving model to /floyd/home/m9_t2.h5\n",
      "Epoch 30/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 0.9292 - acc: 0.7012 - val_loss: 1.8122 - val_acc: 0.6995\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.68953 to 0.69950, saving model to /floyd/home/m9_t2.h5\n",
      "CPU times: user 56min 6s, sys: 6min 52s, total: 1h 2min 59s\n",
      "Wall time: 39min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m9_t2_cp = ModelCheckpoint(filepath=f'{model_path}m9_t2.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m9_t2_history = m9_t2.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m9_t2_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m9_t2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.5884 - acc: 0.1756 - val_loss: 2.8142 - val_acc: 0.2574\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.25743, saving model to /floyd/home/m9_t3.h5\n",
      "Epoch 2/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.2643 - acc: 0.2670 - val_loss: 2.5106 - val_acc: 0.3753\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.25743 to 0.37531, saving model to /floyd/home/m9_t3.h5\n",
      "Epoch 3/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.1260 - acc: 0.3073 - val_loss: 2.1820 - val_acc: 0.3304\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.37531\n",
      "Epoch 4/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.0062 - acc: 0.3448 - val_loss: 2.5495 - val_acc: 0.4539\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.37531 to 0.45387, saving model to /floyd/home/m9_t3.h5\n",
      "Epoch 5/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.9028 - acc: 0.3896 - val_loss: 1.9529 - val_acc: 0.4763\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.45387 to 0.47631, saving model to /floyd/home/m9_t3.h5\n",
      "Epoch 6/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.8473 - acc: 0.4068 - val_loss: 1.1874 - val_acc: 0.5312\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.47631 to 0.53117, saving model to /floyd/home/m9_t3.h5\n",
      "Epoch 7/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.7819 - acc: 0.4356 - val_loss: 1.7032 - val_acc: 0.5087\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.53117\n",
      "Epoch 8/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.7135 - acc: 0.4505 - val_loss: 0.8984 - val_acc: 0.4963\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.53117\n",
      "Epoch 9/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6716 - acc: 0.4640 - val_loss: 0.9011 - val_acc: 0.5087\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.53117\n",
      "Epoch 10/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6154 - acc: 0.4832 - val_loss: 1.0491 - val_acc: 0.5673\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.53117 to 0.56733, saving model to /floyd/home/m9_t3.h5\n",
      "Epoch 11/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.5875 - acc: 0.4962 - val_loss: 2.0314 - val_acc: 0.5611\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.56733\n",
      "Epoch 12/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.5468 - acc: 0.5037 - val_loss: 1.3874 - val_acc: 0.5574\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.56733\n",
      "Epoch 13/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.4860 - acc: 0.5241 - val_loss: 1.5607 - val_acc: 0.5723\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.56733 to 0.57232, saving model to /floyd/home/m9_t3.h5\n",
      "Epoch 14/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.4678 - acc: 0.5262 - val_loss: 2.0315 - val_acc: 0.5574\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.57232\n",
      "Epoch 15/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.4117 - acc: 0.5505 - val_loss: 0.9779 - val_acc: 0.6097\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.57232 to 0.60973, saving model to /floyd/home/m9_t3.h5\n",
      "Epoch 16/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.4030 - acc: 0.5438 - val_loss: 1.6837 - val_acc: 0.5810\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.60973\n",
      "Epoch 17/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.3729 - acc: 0.5622 - val_loss: 0.7172 - val_acc: 0.5486\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.60973\n",
      "Epoch 18/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.3353 - acc: 0.5700 - val_loss: 1.2102 - val_acc: 0.6060\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.60973\n",
      "Epoch 19/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.3052 - acc: 0.5853 - val_loss: 1.1285 - val_acc: 0.6010\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.60973\n",
      "Epoch 20/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.2600 - acc: 0.5946 - val_loss: 1.7586 - val_acc: 0.5960\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.60973\n",
      "Epoch 21/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.2408 - acc: 0.5938 - val_loss: 0.9376 - val_acc: 0.5960\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.60973\n",
      "Epoch 22/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.2165 - acc: 0.6125 - val_loss: 1.0989 - val_acc: 0.6085\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.60973\n",
      "Epoch 23/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.2026 - acc: 0.6112 - val_loss: 1.1275 - val_acc: 0.5848\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.60973\n",
      "Epoch 24/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.1567 - acc: 0.6309 - val_loss: 1.8904 - val_acc: 0.6559\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.60973 to 0.65586, saving model to /floyd/home/m9_t3.h5\n",
      "Epoch 25/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.1395 - acc: 0.6401 - val_loss: 1.0466 - val_acc: 0.6160\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.65586\n",
      "Epoch 26/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.1255 - acc: 0.6425 - val_loss: 1.1433 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.65586 to 0.65835, saving model to /floyd/home/m9_t3.h5\n",
      "Epoch 27/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.0949 - acc: 0.6405 - val_loss: 0.1793 - val_acc: 0.6683\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.65835 to 0.66833, saving model to /floyd/home/m9_t3.h5\n",
      "Epoch 28/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.0571 - acc: 0.6579 - val_loss: 1.9097 - val_acc: 0.6771\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.66833 to 0.67706, saving model to /floyd/home/m9_t3.h5\n",
      "Epoch 29/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.0466 - acc: 0.6640 - val_loss: 0.4762 - val_acc: 0.6234\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.67706\n",
      "Epoch 30/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.0218 - acc: 0.6657 - val_loss: 1.6278 - val_acc: 0.6322\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.67706\n",
      "CPU times: user 56min 2s, sys: 6min 51s, total: 1h 2min 53s\n",
      "Wall time: 39min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m9_t3_cp = ModelCheckpoint(filepath=f'{model_path}m9_t3.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m9_t3_history = m9_t3.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m9_t3_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m9_t3_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.6278 - acc: 0.1610 - val_loss: 2.4638 - val_acc: 0.2958\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.29579, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 2/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.2495 - acc: 0.2780 - val_loss: 2.2817 - val_acc: 0.3741\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.29579 to 0.37406, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 3/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.1286 - acc: 0.3198 - val_loss: 1.9328 - val_acc: 0.3753\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.37406 to 0.37531, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 4/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.0438 - acc: 0.3400 - val_loss: 1.7933 - val_acc: 0.4165\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.37531 to 0.41646, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 5/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.9573 - acc: 0.3674 - val_loss: 2.8352 - val_acc: 0.4514\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.41646 to 0.45137, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 6/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.9003 - acc: 0.3899 - val_loss: 0.9525 - val_acc: 0.4526\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.45137 to 0.45262, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 7/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.8510 - acc: 0.4047 - val_loss: 2.7983 - val_acc: 0.4838\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.45262 to 0.48379, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 8/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.7851 - acc: 0.4257 - val_loss: 1.2073 - val_acc: 0.4788\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.48379\n",
      "Epoch 9/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.7592 - acc: 0.4356 - val_loss: 2.1052 - val_acc: 0.5237\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.48379 to 0.52369, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 10/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.7120 - acc: 0.4479 - val_loss: 1.1395 - val_acc: 0.5461\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.52369 to 0.54613, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 11/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6711 - acc: 0.4663 - val_loss: 1.2339 - val_acc: 0.5162\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.54613\n",
      "Epoch 12/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6307 - acc: 0.4812 - val_loss: 1.1831 - val_acc: 0.5748\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.54613 to 0.57481, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 13/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.5847 - acc: 0.4875 - val_loss: 2.1690 - val_acc: 0.5387\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.57481\n",
      "Epoch 14/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.5672 - acc: 0.4937 - val_loss: 1.8521 - val_acc: 0.5349\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.57481\n",
      "Epoch 15/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.5300 - acc: 0.5067 - val_loss: 1.5941 - val_acc: 0.5935\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.57481 to 0.59352, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 16/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.4914 - acc: 0.5147 - val_loss: 1.1445 - val_acc: 0.5998\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.59352 to 0.59975, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 17/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.4737 - acc: 0.5294 - val_loss: 1.1337 - val_acc: 0.5623\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.59975\n",
      "Epoch 18/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.4284 - acc: 0.5437 - val_loss: 1.3361 - val_acc: 0.5973\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.59975\n",
      "Epoch 19/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.4007 - acc: 0.5496 - val_loss: 1.1644 - val_acc: 0.5262\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.59975\n",
      "Epoch 20/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.3825 - acc: 0.5574 - val_loss: 0.8463 - val_acc: 0.6022\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.59975 to 0.60224, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 21/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.3501 - acc: 0.5667 - val_loss: 0.9978 - val_acc: 0.6122\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.60224 to 0.61222, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 22/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.3369 - acc: 0.5681 - val_loss: 1.5148 - val_acc: 0.5673\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.61222\n",
      "Epoch 23/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.2970 - acc: 0.5801 - val_loss: 1.4691 - val_acc: 0.6147\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.61222 to 0.61471, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 24/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.2789 - acc: 0.5831 - val_loss: 1.0269 - val_acc: 0.6259\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.61471 to 0.62594, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 25/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.2619 - acc: 0.5989 - val_loss: 0.9829 - val_acc: 0.6222\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.62594\n",
      "Epoch 26/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.2534 - acc: 0.6009 - val_loss: 0.4159 - val_acc: 0.6135\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.62594\n",
      "Epoch 27/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.2186 - acc: 0.6054 - val_loss: 0.6681 - val_acc: 0.5611\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.62594\n",
      "Epoch 28/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.1951 - acc: 0.6175 - val_loss: 0.7645 - val_acc: 0.6072\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.62594\n",
      "Epoch 29/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.1782 - acc: 0.6194 - val_loss: 0.8644 - val_acc: 0.6297\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.62594 to 0.62968, saving model to /floyd/home/m9_t4.h5\n",
      "Epoch 30/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.1563 - acc: 0.6274 - val_loss: 1.7950 - val_acc: 0.6446\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.62968 to 0.64464, saving model to /floyd/home/m9_t4.h5\n",
      "CPU times: user 56min 15s, sys: 6min 51s, total: 1h 3min 6s\n",
      "Wall time: 39min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m9_t4_cp = ModelCheckpoint(filepath=f'{model_path}m9_t4.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m9_t4_history = m9_t4.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m9_t4_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m9_t4_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.7282 - acc: 0.1422 - val_loss: 2.3298 - val_acc: 0.2475\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.24752, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 2/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.4116 - acc: 0.2315 - val_loss: 2.0152 - val_acc: 0.3117\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.24752 to 0.31172, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 3/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.2545 - acc: 0.2767 - val_loss: 1.7269 - val_acc: 0.3616\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.31172 to 0.36160, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 4/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.1805 - acc: 0.2964 - val_loss: 1.6684 - val_acc: 0.3616\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.36160\n",
      "Epoch 5/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.1026 - acc: 0.3233 - val_loss: 1.7958 - val_acc: 0.3853\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.36160 to 0.38529, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 6/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.0554 - acc: 0.3348 - val_loss: 1.7878 - val_acc: 0.4177\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.38529 to 0.41771, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 7/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.0141 - acc: 0.3463 - val_loss: 1.9636 - val_acc: 0.4177\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.41771\n",
      "Epoch 8/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.9684 - acc: 0.3599 - val_loss: 2.4371 - val_acc: 0.4352\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.41771 to 0.43516, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 9/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.9384 - acc: 0.3719 - val_loss: 1.4559 - val_acc: 0.4489\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.43516 to 0.44888, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 10/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.9033 - acc: 0.3852 - val_loss: 0.8775 - val_acc: 0.4613\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.44888 to 0.46135, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 11/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.8663 - acc: 0.3977 - val_loss: 1.9166 - val_acc: 0.4451\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.46135\n",
      "Epoch 12/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.8557 - acc: 0.4101 - val_loss: 2.1267 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.46135 to 0.49002, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 13/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.8142 - acc: 0.4196 - val_loss: 0.8458 - val_acc: 0.4925\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.49002 to 0.49252, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 14/30\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.7810 - acc: 0.4269 - val_loss: 1.8393 - val_acc: 0.5075\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.49252 to 0.50748, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 15/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.7725 - acc: 0.4306 - val_loss: 1.0940 - val_acc: 0.5012\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.50748\n",
      "Epoch 16/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.7381 - acc: 0.4351 - val_loss: 0.8428 - val_acc: 0.5062\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.50748\n",
      "Epoch 17/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.7384 - acc: 0.4411 - val_loss: 1.8701 - val_acc: 0.5287\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.50748 to 0.52868, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 18/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.7185 - acc: 0.4446 - val_loss: 1.9384 - val_acc: 0.5050\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.52868\n",
      "Epoch 19/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.6880 - acc: 0.4579 - val_loss: 1.2701 - val_acc: 0.4925\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.52868\n",
      "Epoch 20/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6777 - acc: 0.4626 - val_loss: 2.3129 - val_acc: 0.5150\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.52868\n",
      "Epoch 21/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6476 - acc: 0.4674 - val_loss: 3.6783 - val_acc: 0.4975\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.52868\n",
      "Epoch 22/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6343 - acc: 0.4728 - val_loss: 1.2317 - val_acc: 0.4975\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.52868\n",
      "Epoch 23/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6041 - acc: 0.4795 - val_loss: 1.1582 - val_acc: 0.5436\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.52868 to 0.54364, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 24/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6079 - acc: 0.4816 - val_loss: 1.1840 - val_acc: 0.5324\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.54364\n",
      "Epoch 25/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.5989 - acc: 0.4862 - val_loss: 1.4776 - val_acc: 0.5524\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.54364 to 0.55237, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 26/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.5748 - acc: 0.4911 - val_loss: 1.6120 - val_acc: 0.5150\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.55237\n",
      "Epoch 27/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.5560 - acc: 0.5020 - val_loss: 2.1018 - val_acc: 0.5636\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.55237 to 0.56359, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 28/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.5316 - acc: 0.5072 - val_loss: 1.5260 - val_acc: 0.5574\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.56359\n",
      "Epoch 29/30\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.5092 - acc: 0.5146 - val_loss: 0.8384 - val_acc: 0.5761\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.56359 to 0.57606, saving model to /floyd/home/m9_t5.h5\n",
      "Epoch 30/30\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.5144 - acc: 0.5142 - val_loss: 0.6943 - val_acc: 0.5661\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.57606\n",
      "CPU times: user 56min 31s, sys: 6min 55s, total: 1h 3min 27s\n",
      "Wall time: 39min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m9_t5_cp = ModelCheckpoint(filepath=f'{model_path}m9_t5.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m9_t5_history = m9_t5.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m9_t5_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m9_t5_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary for model names, models, and histories from respective lists\n",
    "models_dict = {i:[j,k] for i,j,k in zip(model_names,model_list,model_hists)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 2s 20ms/step\n",
      "m9_t1 Val Accuracy: 71.36%\n",
      "m9_t1 Val Loss: 0.5447\n",
      "---\n",
      "102/102 [==============================] - 2s 19ms/step\n",
      "m9_t2 Val Accuracy: 68.52%\n",
      "m9_t2 Val Loss: 0.1631\n",
      "---\n",
      "102/102 [==============================] - 2s 20ms/step\n",
      "m9_t3 Val Accuracy: 67.53%\n",
      "m9_t3 Val Loss: 0.7804\n",
      "---\n",
      "102/102 [==============================] - 2s 19ms/step\n",
      "m9_t4 Val Accuracy: 63.09%\n",
      "m9_t4 Val Loss: 1.3448\n",
      "---\n",
      "102/102 [==============================] - 2s 20ms/step\n",
      "m9_t5 Val Accuracy: 56.54%\n",
      "m9_t5 Val Loss: 0.4567\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# evaluating models on validation set\n",
    "for key, value in models_dict.items():\n",
    "    model = models.load_model(f'{model_path}{key}.h5')\n",
    "    (val_loss, val_accuracy) = model.evaluate(val_generator,verbose=1)\n",
    "    print(f'{key} Val Accuracy: {round((val_accuracy*100),2)}%')\n",
    "    print(f'{key} Val Loss: {round(val_loss,4)}')\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m9_t1_history saved in /floyd/home/\n",
      "m9_t2_history saved in /floyd/home/\n",
      "m9_t3_history saved in /floyd/home/\n",
      "m9_t4_history saved in /floyd/home/\n",
      "m9_t5_history saved in /floyd/home/\n"
     ]
    }
   ],
   "source": [
    "# saving training histories\n",
    "for key, value in models_dict.items():\n",
    "    with open(f'{model_path}{key}_history', 'wb') as file_pi:\n",
    "        pickle.dump(value[1].history, file_pi)\n",
    "    print(f'{key}_history saved in {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
