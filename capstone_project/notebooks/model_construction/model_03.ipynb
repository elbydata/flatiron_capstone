{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the construction and training of the model iterations and various experiments. The notebook is split up into four sections: training mode selection (where the model will run), set-up, model constrution, and training. \n",
    "\n",
    "Evaluation will take place in the *model_optimization_and_evaluation.ipynb* notebook found in the *notebooks* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import applications \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Training Mode Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, specify the training mode for the model. This will determine the location from which the source data is drawn, and to which the trained models (and training histories) are saved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **training_mode = 'floydhub'** (runs on Floydhub)\n",
    "- **training_mode = 'local'** (runs on local disk and processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select training mode\n",
    "training_mode = 'floydhub'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory base paths\n",
    "data_path_local = '../../data/0002_array_data/train_data/'\n",
    "model_path_local = '../../notebooks/model_construction/saved_models/'\n",
    "data_path_floydhub = '/floyd/input/capstone_mushrooms/'\n",
    "model_path_floydhub = '/floyd/home/'\n",
    "\n",
    "# setting directory paths based on training mode selection\n",
    "if training_mode == 'floydhub':\n",
    "    data_path = data_path_floydhub\n",
    "    model_path = model_path_floydhub\n",
    "elif training_mode == 'local':\n",
    "    data_path = data_path_local\n",
    "    model_path = model_path_local\n",
    "else:\n",
    "    raise Exception('Please choose valid training mode: \"floydhub\" or \"local\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the training and validation data subsets\n",
    "X_train = np.load(f'{data_path}X_train_data.npy')\n",
    "y_train = np.load(f'{data_path}y_train_data.npy')\n",
    "X_val = np.load(f'{data_path}X_val_data.npy')\n",
    "y_val = np.load(f'{data_path}y_val_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting training parameters\n",
    "batch_size = 32\n",
    "n_classes = 20\n",
    "n_epochs = 15\n",
    "img_shape = X_train.shape[1:]\n",
    "model_names = []\n",
    "model_list = []\n",
    "model_hists = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 1 - SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m3_t1 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m3_t1.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=img_shape, padding='same'))\n",
    "m3_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t1.add(layers.Conv2D(64,(3,3), activation='relu', padding='same'))\n",
    "m3_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t1.add(layers.Conv2D(128,(3,3), activation='relu', padding='same'))\n",
    "m3_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t1.add(layers.Conv2D(256,(3,3), activation='relu', padding='same'))\n",
    "m3_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m3_t1.add(layers.Flatten())\n",
    "m3_t1.add(layers.Dense(512, activation='relu'))\n",
    "m3_t1.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m3_t1.summary()\n",
    "model_names.append('m3_t1')\n",
    "model_list.append(m3_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 2 - RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m3_t2 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m3_t2.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=img_shape, padding='same'))\n",
    "m3_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t2.add(layers.Conv2D(64,(3,3), activation='relu', padding='same'))\n",
    "m3_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t2.add(layers.Conv2D(128,(3,3), activation='relu', padding='same'))\n",
    "m3_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t2.add(layers.Conv2D(256,(3,3), activation='relu', padding='same'))\n",
    "m3_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m3_t2.add(layers.Flatten())\n",
    "m3_t2.add(layers.Dense(512, activation='relu'))\n",
    "m3_t2.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m3_t2.summary()\n",
    "model_names.append('m3_t2')\n",
    "model_list.append(m3_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 3 - Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m3_t3 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m3_t3.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=img_shape, padding='same'))\n",
    "m3_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t3.add(layers.Conv2D(64,(3,3), activation='relu', padding='same'))\n",
    "m3_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t3.add(layers.Conv2D(128,(3,3), activation='relu', padding='same'))\n",
    "m3_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t3.add(layers.Conv2D(256,(3,3), activation='relu', padding='same'))\n",
    "m3_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m3_t3.add(layers.Flatten())\n",
    "m3_t3.add(layers.Dense(512, activation='relu'))\n",
    "m3_t3.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m3_t3.summary()\n",
    "model_names.append('m3_t3')\n",
    "model_list.append(m3_t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 4 - Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m3_t4 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m3_t4.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=img_shape, padding='same'))\n",
    "m3_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t4.add(layers.Conv2D(64,(3,3), activation='relu', padding='same'))\n",
    "m3_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t4.add(layers.Conv2D(128,(3,3), activation='relu', padding='same'))\n",
    "m3_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t4.add(layers.Conv2D(256,(3,3), activation='relu', padding='same'))\n",
    "m3_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m3_t4.add(layers.Flatten())\n",
    "m3_t4.add(layers.Dense(512, activation='relu'))\n",
    "m3_t4.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m3_t4.summary()\n",
    "model_names.append('m3_t4')\n",
    "model_list.append(m3_t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 5 - Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m3_t5 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m3_t5.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=img_shape, padding='same'))\n",
    "m3_t5.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t5.add(layers.Conv2D(64,(3,3), activation='relu', padding='same'))\n",
    "m3_t5.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t5.add(layers.Conv2D(128,(3,3), activation='relu', padding='same'))\n",
    "m3_t5.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t5.add(layers.Conv2D(256,(3,3), activation='relu', padding='same'))\n",
    "m3_t5.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m3_t5.add(layers.Flatten())\n",
    "m3_t5.add(layers.Dense(512, activation='relu'))\n",
    "m3_t5.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m3_t5.summary()\n",
    "model_names.append('m3_t5')\n",
    "model_list.append(m3_t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 6 - Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m3_t6 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m3_t6.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=img_shape, padding='same'))\n",
    "m3_t6.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t6.add(layers.Conv2D(64,(3,3), activation='relu', padding='same'))\n",
    "m3_t6.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t6.add(layers.Conv2D(128,(3,3), activation='relu', padding='same'))\n",
    "m3_t6.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t6.add(layers.Conv2D(256,(3,3), activation='relu', padding='same'))\n",
    "m3_t6.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m3_t6.add(layers.Flatten())\n",
    "m3_t6.add(layers.Dense(512, activation='relu'))\n",
    "m3_t6.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m3_t6.summary()\n",
    "model_names.append('m3_t6')\n",
    "model_list.append(m3_t6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 7 - Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m3_t7 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m3_t7.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=img_shape, padding='same'))\n",
    "m3_t7.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t7.add(layers.Conv2D(64,(3,3), activation='relu', padding='same'))\n",
    "m3_t7.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t7.add(layers.Conv2D(128,(3,3), activation='relu', padding='same'))\n",
    "m3_t7.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m3_t7.add(layers.Conv2D(256,(3,3), activation='relu', padding='same'))\n",
    "m3_t7.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m3_t7.add(layers.Flatten())\n",
    "m3_t7.add(layers.Dense(512, activation='relu'))\n",
    "m3_t7.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m3_t7.summary()\n",
    "model_names.append('m3_t7')\n",
    "model_list.append(m3_t7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up standardization and augmentation parameters\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.3,\n",
    "                                   height_shift_range=0.3,\n",
    "                                   shear_range=0.3,\n",
    "                                   zoom_range=0.3,\n",
    "                                   fill_mode='nearest',\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 268 ms, sys: 1.06 s, total: 1.33 s\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data standardization and augmentation\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling loss functions\n",
    "m3_t1.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['acc'])\n",
    "m3_t2.compile(loss='categorical_crossentropy', optimizer='RMSProp', metrics=['acc'])\n",
    "m3_t3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "m3_t4.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['acc'])\n",
    "m3_t5.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['acc'])\n",
    "m3_t6.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['acc'])\n",
    "m3_t7.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "253/253 [==============================] - 134s 529ms/step - loss: 2.9718 - acc: 0.0867 - val_loss: 2.9650 - val_acc: 0.0825\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.08250, saving model to /floyd/home/m3_t1.h5\n",
      "Epoch 2/15\n",
      "253/253 [==============================] - 72s 286ms/step - loss: 2.9370 - acc: 0.0968 - val_loss: 2.8417 - val_acc: 0.1260\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.08250 to 0.12596, saving model to /floyd/home/m3_t1.h5\n",
      "Epoch 3/15\n",
      "253/253 [==============================] - 73s 290ms/step - loss: 2.7659 - acc: 0.1300 - val_loss: 2.6282 - val_acc: 0.1838\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.12596 to 0.18380, saving model to /floyd/home/m3_t1.h5\n",
      "Epoch 4/15\n",
      "253/253 [==============================] - 72s 286ms/step - loss: 2.6400 - acc: 0.1498 - val_loss: 2.4881 - val_acc: 0.1915\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.18380 to 0.19152, saving model to /floyd/home/m3_t1.h5\n",
      "Epoch 5/15\n",
      "253/253 [==============================] - 74s 291ms/step - loss: 2.5727 - acc: 0.1700 - val_loss: 2.6089 - val_acc: 0.1735\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.19152\n",
      "Epoch 6/15\n",
      "253/253 [==============================] - 73s 289ms/step - loss: 2.5155 - acc: 0.1814 - val_loss: 2.3124 - val_acc: 0.2172\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.19152 to 0.21722, saving model to /floyd/home/m3_t1.h5\n",
      "Epoch 7/15\n",
      "253/253 [==============================] - 73s 288ms/step - loss: 2.4555 - acc: 0.2020 - val_loss: 2.1139 - val_acc: 0.2172\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.21722\n",
      "Epoch 8/15\n",
      "253/253 [==============================] - 72s 286ms/step - loss: 2.4032 - acc: 0.2260 - val_loss: 2.1286 - val_acc: 0.2661\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.21722 to 0.26607, saving model to /floyd/home/m3_t1.h5\n",
      "Epoch 9/15\n",
      "253/253 [==============================] - 73s 287ms/step - loss: 2.3354 - acc: 0.2368 - val_loss: 2.4634 - val_acc: 0.3458\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.26607 to 0.34576, saving model to /floyd/home/m3_t1.h5\n",
      "Epoch 10/15\n",
      "253/253 [==============================] - 73s 288ms/step - loss: 2.2803 - acc: 0.2592 - val_loss: 1.9149 - val_acc: 0.3560\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.34576 to 0.35604, saving model to /floyd/home/m3_t1.h5\n",
      "Epoch 11/15\n",
      "253/253 [==============================] - 72s 285ms/step - loss: 2.2340 - acc: 0.2786 - val_loss: 1.9572 - val_acc: 0.3470\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.35604\n",
      "Epoch 12/15\n",
      "253/253 [==============================] - 72s 285ms/step - loss: 2.1906 - acc: 0.2930 - val_loss: 2.2859 - val_acc: 0.3856\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.35604 to 0.38560, saving model to /floyd/home/m3_t1.h5\n",
      "Epoch 13/15\n",
      "253/253 [==============================] - 72s 286ms/step - loss: 2.1718 - acc: 0.2922 - val_loss: 1.7938 - val_acc: 0.3509\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.38560\n",
      "Epoch 14/15\n",
      "253/253 [==============================] - 72s 285ms/step - loss: 2.1418 - acc: 0.3077 - val_loss: 1.8077 - val_acc: 0.3753\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.38560\n",
      "Epoch 15/15\n",
      "253/253 [==============================] - 72s 286ms/step - loss: 2.1044 - acc: 0.3132 - val_loss: 2.1451 - val_acc: 0.4165\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.38560 to 0.41645, saving model to /floyd/home/m3_t1.h5\n",
      "CPU times: user 21min 36s, sys: 1min 25s, total: 23min 1s\n",
      "Wall time: 19min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m3_t1_cp = ModelCheckpoint(filepath=f'{model_path}m3_t1.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m3_t1_history = m3_t1.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m3_t1_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m3_t1_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "253/253 [==============================] - 74s 291ms/step - loss: 2.9375 - acc: 0.1124 - val_loss: 2.6489 - val_acc: 0.1900\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.19000, saving model to /floyd/home/m3_t2.h5\n",
      "Epoch 2/15\n",
      "253/253 [==============================] - 73s 290ms/step - loss: 2.4864 - acc: 0.2036 - val_loss: 2.1616 - val_acc: 0.2712\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.19000 to 0.27121, saving model to /floyd/home/m3_t2.h5\n",
      "Epoch 3/15\n",
      "253/253 [==============================] - 74s 294ms/step - loss: 2.2883 - acc: 0.2650 - val_loss: 1.9439 - val_acc: 0.3175\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.27121 to 0.31748, saving model to /floyd/home/m3_t2.h5\n",
      "Epoch 4/15\n",
      "253/253 [==============================] - 74s 293ms/step - loss: 2.1794 - acc: 0.3062 - val_loss: 1.9158 - val_acc: 0.2982\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.31748\n",
      "Epoch 5/15\n",
      "253/253 [==============================] - 74s 292ms/step - loss: 2.1159 - acc: 0.3284 - val_loss: 1.6203 - val_acc: 0.4229\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.31748 to 0.42288, saving model to /floyd/home/m3_t2.h5\n",
      "Epoch 6/15\n",
      "253/253 [==============================] - 74s 293ms/step - loss: 2.0579 - acc: 0.3471 - val_loss: 1.8131 - val_acc: 0.4177\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.42288\n",
      "Epoch 7/15\n",
      "253/253 [==============================] - 73s 290ms/step - loss: 1.9851 - acc: 0.3695 - val_loss: 1.8955 - val_acc: 0.4499\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.42288 to 0.44987, saving model to /floyd/home/m3_t2.h5\n",
      "Epoch 8/15\n",
      "253/253 [==============================] - 74s 293ms/step - loss: 1.9378 - acc: 0.3915 - val_loss: 1.4991 - val_acc: 0.5347\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.44987 to 0.53470, saving model to /floyd/home/m3_t2.h5\n",
      "Epoch 9/15\n",
      "253/253 [==============================] - 74s 291ms/step - loss: 1.9067 - acc: 0.3966 - val_loss: 1.4208 - val_acc: 0.4614\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.53470\n",
      "Epoch 10/15\n",
      "253/253 [==============================] - 74s 291ms/step - loss: 1.8672 - acc: 0.4066 - val_loss: 1.8323 - val_acc: 0.4769\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.53470\n",
      "Epoch 11/15\n",
      "253/253 [==============================] - 74s 291ms/step - loss: 1.8425 - acc: 0.4186 - val_loss: 2.0586 - val_acc: 0.4653\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.53470\n",
      "Epoch 12/15\n",
      "253/253 [==============================] - 75s 295ms/step - loss: 1.8129 - acc: 0.4277 - val_loss: 1.9821 - val_acc: 0.5026\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.53470\n",
      "Epoch 13/15\n",
      "253/253 [==============================] - 74s 291ms/step - loss: 1.8052 - acc: 0.4316 - val_loss: 1.3180 - val_acc: 0.5283\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.53470\n",
      "Epoch 14/15\n",
      "253/253 [==============================] - 74s 293ms/step - loss: 1.7746 - acc: 0.4351 - val_loss: 1.8532 - val_acc: 0.4987\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.53470\n",
      "Epoch 15/15\n",
      "253/253 [==============================] - 73s 288ms/step - loss: 1.7607 - acc: 0.4511 - val_loss: 1.5069 - val_acc: 0.5013\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.53470\n",
      "CPU times: user 22min 14s, sys: 1min 34s, total: 23min 49s\n",
      "Wall time: 18min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m3_t2_cp = ModelCheckpoint(filepath=f'{model_path}m3_t2.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m3_t2_history = m3_t2.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m3_t2_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m3_t2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "253/253 [==============================] - 73s 290ms/step - loss: 2.8488 - acc: 0.1112 - val_loss: 2.2923 - val_acc: 0.1700\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.17000, saving model to /floyd/home/m3_t3.h5\n",
      "Epoch 2/15\n",
      "253/253 [==============================] - 73s 288ms/step - loss: 2.5396 - acc: 0.1755 - val_loss: 2.3455 - val_acc: 0.2481\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.17000 to 0.24807, saving model to /floyd/home/m3_t3.h5\n",
      "Epoch 3/15\n",
      "253/253 [==============================] - 73s 287ms/step - loss: 2.3964 - acc: 0.2169 - val_loss: 1.9619 - val_acc: 0.2905\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.24807 to 0.29049, saving model to /floyd/home/m3_t3.h5\n",
      "Epoch 4/15\n",
      "253/253 [==============================] - 72s 286ms/step - loss: 2.2664 - acc: 0.2507 - val_loss: 2.0215 - val_acc: 0.3573\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.29049 to 0.35733, saving model to /floyd/home/m3_t3.h5\n",
      "Epoch 5/15\n",
      "253/253 [==============================] - 72s 284ms/step - loss: 2.1698 - acc: 0.2916 - val_loss: 1.5620 - val_acc: 0.3830\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.35733 to 0.38303, saving model to /floyd/home/m3_t3.h5\n",
      "Epoch 6/15\n",
      "253/253 [==============================] - 73s 287ms/step - loss: 2.0941 - acc: 0.3158 - val_loss: 1.8282 - val_acc: 0.3792\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.38303\n",
      "Epoch 7/15\n",
      "253/253 [==============================] - 71s 283ms/step - loss: 2.0286 - acc: 0.3362 - val_loss: 1.9468 - val_acc: 0.3856\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.38303 to 0.38560, saving model to /floyd/home/m3_t3.h5\n",
      "Epoch 8/15\n",
      "253/253 [==============================] - 71s 281ms/step - loss: 1.9573 - acc: 0.3658 - val_loss: 1.5521 - val_acc: 0.4422\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.38560 to 0.44216, saving model to /floyd/home/m3_t3.h5\n",
      "Epoch 9/15\n",
      "253/253 [==============================] - 71s 280ms/step - loss: 1.9132 - acc: 0.3783 - val_loss: 1.7174 - val_acc: 0.4563\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.44216 to 0.45630, saving model to /floyd/home/m3_t3.h5\n",
      "Epoch 10/15\n",
      "253/253 [==============================] - 71s 281ms/step - loss: 1.8669 - acc: 0.3934 - val_loss: 1.8973 - val_acc: 0.4627\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.45630 to 0.46272, saving model to /floyd/home/m3_t3.h5\n",
      "Epoch 11/15\n",
      "253/253 [==============================] - 71s 282ms/step - loss: 1.8186 - acc: 0.4148 - val_loss: 1.4366 - val_acc: 0.4730\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.46272 to 0.47301, saving model to /floyd/home/m3_t3.h5\n",
      "Epoch 12/15\n",
      "253/253 [==============================] - 71s 281ms/step - loss: 1.7766 - acc: 0.4250 - val_loss: 2.0098 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.47301 to 0.50000, saving model to /floyd/home/m3_t3.h5\n",
      "Epoch 13/15\n",
      "253/253 [==============================] - 71s 281ms/step - loss: 1.7459 - acc: 0.4290 - val_loss: 2.1754 - val_acc: 0.5283\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.50000 to 0.52828, saving model to /floyd/home/m3_t3.h5\n",
      "Epoch 14/15\n",
      "253/253 [==============================] - 71s 281ms/step - loss: 1.7056 - acc: 0.4417 - val_loss: 1.8489 - val_acc: 0.4589\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.52828\n",
      "Epoch 15/15\n",
      "253/253 [==============================] - 71s 281ms/step - loss: 1.6842 - acc: 0.4508 - val_loss: 1.3674 - val_acc: 0.5283\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.52828\n",
      "CPU times: user 21min 55s, sys: 1min 42s, total: 23min 38s\n",
      "Wall time: 18min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m3_t3_cp = ModelCheckpoint(filepath=f'{model_path}m3_t3.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m3_t3_history = m3_t3.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m3_t3_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m3_t3_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "253/253 [==============================] - 73s 287ms/step - loss: 2.7992 - acc: 0.1165 - val_loss: 2.4084 - val_acc: 0.1612\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.16125, saving model to /floyd/home/m3_t4.h5\n",
      "Epoch 2/15\n",
      "253/253 [==============================] - 72s 285ms/step - loss: 2.5447 - acc: 0.1673 - val_loss: 2.2788 - val_acc: 0.2339\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.16125 to 0.23393, saving model to /floyd/home/m3_t4.h5\n",
      "Epoch 3/15\n",
      "253/253 [==============================] - 73s 287ms/step - loss: 2.4040 - acc: 0.2211 - val_loss: 2.4314 - val_acc: 0.2841\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.23393 to 0.28406, saving model to /floyd/home/m3_t4.h5\n",
      "Epoch 4/15\n",
      "253/253 [==============================] - 72s 286ms/step - loss: 2.2662 - acc: 0.2630 - val_loss: 2.3096 - val_acc: 0.3239\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.28406 to 0.32391, saving model to /floyd/home/m3_t4.h5\n",
      "Epoch 5/15\n",
      "253/253 [==============================] - 72s 285ms/step - loss: 2.1711 - acc: 0.2925 - val_loss: 1.8507 - val_acc: 0.3355\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.32391 to 0.33548, saving model to /floyd/home/m3_t4.h5\n",
      "Epoch 6/15\n",
      "253/253 [==============================] - 72s 283ms/step - loss: 2.0914 - acc: 0.3258 - val_loss: 1.6537 - val_acc: 0.3650\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.33548 to 0.36504, saving model to /floyd/home/m3_t4.h5\n",
      "Epoch 7/15\n",
      "253/253 [==============================] - 71s 281ms/step - loss: 2.0441 - acc: 0.3427 - val_loss: 2.1216 - val_acc: 0.4512\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.36504 to 0.45116, saving model to /floyd/home/m3_t4.h5\n",
      "Epoch 8/15\n",
      "253/253 [==============================] - 71s 282ms/step - loss: 1.9840 - acc: 0.3566 - val_loss: 1.3088 - val_acc: 0.4653\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.45116 to 0.46530, saving model to /floyd/home/m3_t4.h5\n",
      "Epoch 9/15\n",
      "253/253 [==============================] - 71s 280ms/step - loss: 1.9351 - acc: 0.3773 - val_loss: 1.6641 - val_acc: 0.4666\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.46530 to 0.46658, saving model to /floyd/home/m3_t4.h5\n",
      "Epoch 10/15\n",
      "253/253 [==============================] - 71s 282ms/step - loss: 1.8940 - acc: 0.3944 - val_loss: 1.6926 - val_acc: 0.5051\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.46658 to 0.50514, saving model to /floyd/home/m3_t4.h5\n",
      "Epoch 11/15\n",
      "253/253 [==============================] - 71s 282ms/step - loss: 1.8514 - acc: 0.4042 - val_loss: 1.7050 - val_acc: 0.4756\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.50514\n",
      "Epoch 12/15\n",
      "253/253 [==============================] - 72s 283ms/step - loss: 1.8076 - acc: 0.4195 - val_loss: 1.4632 - val_acc: 0.4859\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.50514\n",
      "Epoch 13/15\n",
      "253/253 [==============================] - 71s 280ms/step - loss: 1.7750 - acc: 0.4304 - val_loss: 1.5947 - val_acc: 0.5154\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.50514 to 0.51542, saving model to /floyd/home/m3_t4.h5\n",
      "Epoch 14/15\n",
      "253/253 [==============================] - 71s 281ms/step - loss: 1.7387 - acc: 0.4459 - val_loss: 1.8835 - val_acc: 0.5193\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.51542 to 0.51928, saving model to /floyd/home/m3_t4.h5\n",
      "Epoch 15/15\n",
      "253/253 [==============================] - 71s 279ms/step - loss: 1.7058 - acc: 0.4512 - val_loss: 1.5196 - val_acc: 0.5206\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.51928 to 0.52057, saving model to /floyd/home/m3_t4.h5\n",
      "CPU times: user 22min 3s, sys: 1min 47s, total: 23min 51s\n",
      "Wall time: 18min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m3_t4_cp = ModelCheckpoint(filepath=f'{model_path}m3_t4.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m3_t4_history = m3_t4.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m3_t4_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m3_t4_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "253/253 [==============================] - 72s 286ms/step - loss: 6.4759 - acc: 0.1093 - val_loss: 2.4493 - val_acc: 0.1800\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.18000, saving model to /floyd/home/m3_t5.h5\n",
      "Epoch 2/15\n",
      "253/253 [==============================] - 72s 284ms/step - loss: 2.5433 - acc: 0.1833 - val_loss: 2.1734 - val_acc: 0.2648\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.18000 to 0.26478, saving model to /floyd/home/m3_t5.h5\n",
      "Epoch 3/15\n",
      "253/253 [==============================] - 72s 284ms/step - loss: 2.3922 - acc: 0.2275 - val_loss: 2.0515 - val_acc: 0.2931\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.26478 to 0.29306, saving model to /floyd/home/m3_t5.h5\n",
      "Epoch 4/15\n",
      "253/253 [==============================] - 72s 283ms/step - loss: 2.2814 - acc: 0.2629 - val_loss: 2.0831 - val_acc: 0.3406\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.29306 to 0.34062, saving model to /floyd/home/m3_t5.h5\n",
      "Epoch 5/15\n",
      "253/253 [==============================] - 72s 284ms/step - loss: 2.1815 - acc: 0.2928 - val_loss: 1.9405 - val_acc: 0.3470\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.34062 to 0.34704, saving model to /floyd/home/m3_t5.h5\n",
      "Epoch 6/15\n",
      "253/253 [==============================] - 71s 282ms/step - loss: 2.0878 - acc: 0.3228 - val_loss: 2.2154 - val_acc: 0.3843\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.34704 to 0.38432, saving model to /floyd/home/m3_t5.h5\n",
      "Epoch 7/15\n",
      "253/253 [==============================] - 73s 288ms/step - loss: 2.0626 - acc: 0.3309 - val_loss: 1.7850 - val_acc: 0.3985\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.38432 to 0.39846, saving model to /floyd/home/m3_t5.h5\n",
      "Epoch 8/15\n",
      "253/253 [==============================] - 73s 288ms/step - loss: 2.0075 - acc: 0.3519 - val_loss: 2.2537 - val_acc: 0.3946\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.39846\n",
      "Epoch 9/15\n",
      "253/253 [==============================] - 73s 289ms/step - loss: 1.9569 - acc: 0.3619 - val_loss: 1.8528 - val_acc: 0.4370\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.39846 to 0.43702, saving model to /floyd/home/m3_t5.h5\n",
      "Epoch 10/15\n",
      "253/253 [==============================] - 73s 288ms/step - loss: 1.9284 - acc: 0.3723 - val_loss: 1.8324 - val_acc: 0.4666\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.43702 to 0.46658, saving model to /floyd/home/m3_t5.h5\n",
      "Epoch 11/15\n",
      "253/253 [==============================] - 72s 285ms/step - loss: 1.8882 - acc: 0.3815 - val_loss: 1.2870 - val_acc: 0.4512\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.46658\n",
      "Epoch 12/15\n",
      "253/253 [==============================] - 72s 285ms/step - loss: 1.8695 - acc: 0.3928 - val_loss: 1.8752 - val_acc: 0.4589\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.46658\n",
      "Epoch 13/15\n",
      "253/253 [==============================] - 73s 289ms/step - loss: 1.8472 - acc: 0.4016 - val_loss: 1.4806 - val_acc: 0.4692\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.46658 to 0.46915, saving model to /floyd/home/m3_t5.h5\n",
      "Epoch 14/15\n",
      "253/253 [==============================] - 72s 286ms/step - loss: 1.8135 - acc: 0.4076 - val_loss: 1.8658 - val_acc: 0.4781\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.46915 to 0.47815, saving model to /floyd/home/m3_t5.h5\n",
      "Epoch 15/15\n",
      "253/253 [==============================] - 73s 288ms/step - loss: 1.7886 - acc: 0.4167 - val_loss: 1.4041 - val_acc: 0.5334\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.47815 to 0.53342, saving model to /floyd/home/m3_t5.h5\n",
      "CPU times: user 21min 48s, sys: 1min 34s, total: 23min 23s\n",
      "Wall time: 18min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m3_t5_cp = ModelCheckpoint(filepath=f'{model_path}m3_t5.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m3_t5_history = m3_t5.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m3_t5_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m3_t5_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "253/253 [==============================] - 74s 291ms/step - loss: 2.7881 - acc: 0.1211 - val_loss: 2.3680 - val_acc: 0.1800\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.18000, saving model to /floyd/home/m3_t6.h5\n",
      "Epoch 2/15\n",
      "253/253 [==============================] - 74s 292ms/step - loss: 2.5053 - acc: 0.1913 - val_loss: 2.1748 - val_acc: 0.3046\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.18000 to 0.30463, saving model to /floyd/home/m3_t6.h5\n",
      "Epoch 3/15\n",
      "253/253 [==============================] - 73s 290ms/step - loss: 2.2947 - acc: 0.2505 - val_loss: 2.6751 - val_acc: 0.3406\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.30463 to 0.34062, saving model to /floyd/home/m3_t6.h5\n",
      "Epoch 4/15\n",
      "253/253 [==============================] - 74s 292ms/step - loss: 2.1700 - acc: 0.3003 - val_loss: 2.1819 - val_acc: 0.3483\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.34062 to 0.34833, saving model to /floyd/home/m3_t6.h5\n",
      "Epoch 5/15\n",
      "253/253 [==============================] - 74s 291ms/step - loss: 2.0713 - acc: 0.3353 - val_loss: 1.7165 - val_acc: 0.4293\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.34833 to 0.42931, saving model to /floyd/home/m3_t6.h5\n",
      "Epoch 6/15\n",
      "253/253 [==============================] - 73s 290ms/step - loss: 2.0079 - acc: 0.3576 - val_loss: 1.5607 - val_acc: 0.4576\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.42931 to 0.45758, saving model to /floyd/home/m3_t6.h5\n",
      "Epoch 7/15\n",
      "253/253 [==============================] - 74s 291ms/step - loss: 1.9461 - acc: 0.3700 - val_loss: 1.4268 - val_acc: 0.3843\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.45758\n",
      "Epoch 8/15\n",
      "253/253 [==============================] - 73s 290ms/step - loss: 1.8878 - acc: 0.3971 - val_loss: 1.7326 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.45758 to 0.50000, saving model to /floyd/home/m3_t6.h5\n",
      "Epoch 9/15\n",
      "253/253 [==============================] - 73s 290ms/step - loss: 1.8423 - acc: 0.4125 - val_loss: 1.5863 - val_acc: 0.4846\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.50000\n",
      "Epoch 10/15\n",
      "253/253 [==============================] - 73s 290ms/step - loss: 1.8032 - acc: 0.4122 - val_loss: 1.4264 - val_acc: 0.5116\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.50000 to 0.51157, saving model to /floyd/home/m3_t6.h5\n",
      "Epoch 11/15\n",
      "253/253 [==============================] - 73s 288ms/step - loss: 1.7339 - acc: 0.4464 - val_loss: 1.1616 - val_acc: 0.4781\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.51157\n",
      "Epoch 12/15\n",
      "253/253 [==============================] - 72s 285ms/step - loss: 1.7195 - acc: 0.4432 - val_loss: 1.5938 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.51157 to 0.53985, saving model to /floyd/home/m3_t6.h5\n",
      "Epoch 13/15\n",
      "253/253 [==============================] - 74s 291ms/step - loss: 1.6810 - acc: 0.4572 - val_loss: 1.6541 - val_acc: 0.4769\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.53985\n",
      "Epoch 14/15\n",
      "253/253 [==============================] - 73s 288ms/step - loss: 1.6207 - acc: 0.4814 - val_loss: 1.2481 - val_acc: 0.5540\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.53985 to 0.55398, saving model to /floyd/home/m3_t6.h5\n",
      "Epoch 15/15\n",
      "253/253 [==============================] - 73s 288ms/step - loss: 1.6186 - acc: 0.4796 - val_loss: 1.7073 - val_acc: 0.5450\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.55398\n",
      "CPU times: user 22min 7s, sys: 1min 36s, total: 23min 44s\n",
      "Wall time: 18min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m3_t6_cp = ModelCheckpoint(filepath=f'{model_path}m3_t6.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m3_t6_history = m3_t6.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m3_t6_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m3_t6_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "253/253 [==============================] - 74s 292ms/step - loss: 3.0099 - acc: 0.0931 - val_loss: 2.8263 - val_acc: 0.1450\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.14500, saving model to /floyd/home/m3_t7.h5\n",
      "Epoch 2/15\n",
      "253/253 [==============================] - 73s 288ms/step - loss: 2.8788 - acc: 0.1103 - val_loss: 2.7854 - val_acc: 0.1504\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.14500 to 0.15039, saving model to /floyd/home/m3_t7.h5\n",
      "Epoch 3/15\n",
      "253/253 [==============================] - 73s 288ms/step - loss: 2.8166 - acc: 0.1337 - val_loss: 2.6140 - val_acc: 0.1787\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.15039 to 0.17866, saving model to /floyd/home/m3_t7.h5\n",
      "Epoch 4/15\n",
      "253/253 [==============================] - 72s 286ms/step - loss: 2.5283 - acc: 0.1768 - val_loss: 2.3470 - val_acc: 0.2339\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.17866 to 0.23393, saving model to /floyd/home/m3_t7.h5\n",
      "Epoch 5/15\n",
      "253/253 [==============================] - 73s 289ms/step - loss: 2.4352 - acc: 0.2017 - val_loss: 2.2868 - val_acc: 0.2455\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.23393 to 0.24550, saving model to /floyd/home/m3_t7.h5\n",
      "Epoch 6/15\n",
      "253/253 [==============================] - 72s 285ms/step - loss: 2.3724 - acc: 0.2167 - val_loss: 2.4165 - val_acc: 0.2506\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.24550 to 0.25064, saving model to /floyd/home/m3_t7.h5\n",
      "Epoch 7/15\n",
      "253/253 [==============================] - 72s 285ms/step - loss: 2.3358 - acc: 0.2329 - val_loss: 2.6082 - val_acc: 0.2584\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.25064 to 0.25835, saving model to /floyd/home/m3_t7.h5\n",
      "Epoch 8/15\n",
      "253/253 [==============================] - 72s 284ms/step - loss: 2.2817 - acc: 0.2541 - val_loss: 1.7546 - val_acc: 0.3162\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.25835 to 0.31620, saving model to /floyd/home/m3_t7.h5\n",
      "Epoch 9/15\n",
      "253/253 [==============================] - 72s 284ms/step - loss: 2.2200 - acc: 0.2744 - val_loss: 2.0752 - val_acc: 0.3419\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.31620 to 0.34190, saving model to /floyd/home/m3_t7.h5\n",
      "Epoch 10/15\n",
      "253/253 [==============================] - 71s 282ms/step - loss: 2.1756 - acc: 0.2900 - val_loss: 2.0388 - val_acc: 0.3188\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.34190\n",
      "Epoch 11/15\n",
      "253/253 [==============================] - 72s 284ms/step - loss: 2.1217 - acc: 0.3089 - val_loss: 2.1584 - val_acc: 0.3188\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.34190\n",
      "Epoch 12/15\n",
      "253/253 [==============================] - 72s 285ms/step - loss: 2.0905 - acc: 0.3155 - val_loss: 1.7365 - val_acc: 0.3676\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.34190 to 0.36761, saving model to /floyd/home/m3_t7.h5\n",
      "Epoch 13/15\n",
      "253/253 [==============================] - 71s 282ms/step - loss: 2.0747 - acc: 0.3270 - val_loss: 1.7479 - val_acc: 0.3599\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.36761\n",
      "Epoch 14/15\n",
      "253/253 [==============================] - 71s 281ms/step - loss: 2.0176 - acc: 0.3411 - val_loss: 1.9614 - val_acc: 0.3856\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.36761 to 0.38560, saving model to /floyd/home/m3_t7.h5\n",
      "Epoch 15/15\n",
      "253/253 [==============================] - 71s 281ms/step - loss: 1.9877 - acc: 0.3559 - val_loss: 1.6668 - val_acc: 0.4409\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.38560 to 0.44087, saving model to /floyd/home/m3_t7.h5\n",
      "CPU times: user 22min 20s, sys: 1min 52s, total: 24min 13s\n",
      "Wall time: 18min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m3_t7_cp = ModelCheckpoint(filepath=f'{model_path}m3_t7.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m3_t7_history = m3_t7.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m3_t7_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m3_t7_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary for model names, models, and histories from respective lists\n",
    "models_dict = {i:[j,k] for i,j,k in zip(model_names,model_list,model_hists)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 44ms/step\n",
      "m3_t1 Val Accuracy: 39.75%\n",
      "m3_t1 Val Loss: 2.086\n",
      "---\n",
      "26/26 [==============================] - 1s 43ms/step\n",
      "m3_t2 Val Accuracy: 50.49%\n",
      "m3_t2 Val Loss: 2.0096\n",
      "---\n",
      "26/26 [==============================] - 1s 43ms/step\n",
      "m3_t3 Val Accuracy: 50.37%\n",
      "m3_t3 Val Loss: 1.7346\n",
      "---\n",
      "26/26 [==============================] - 1s 44ms/step\n",
      "m3_t4 Val Accuracy: 51.6%\n",
      "m3_t4 Val Loss: 1.7007\n",
      "---\n",
      "26/26 [==============================] - 1s 46ms/step\n",
      "m3_t5 Val Accuracy: 51.6%\n",
      "m3_t5 Val Loss: 2.0198\n",
      "---\n",
      "26/26 [==============================] - 1s 43ms/step\n",
      "m3_t6 Val Accuracy: 53.83%\n",
      "m3_t6 Val Loss: 1.6315\n",
      "---\n",
      "26/26 [==============================] - 1s 43ms/step\n",
      "m3_t7 Val Accuracy: 42.47%\n",
      "m3_t7 Val Loss: 2.0155\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# evaluating models on validation set\n",
    "for key, value in models_dict.items():\n",
    "    model = models.load_model(f'{model_path}{key}.h5')\n",
    "    (val_loss, val_accuracy) = model.evaluate(val_generator,verbose=1)\n",
    "    print(f'{key} Val Accuracy: {round((val_accuracy*100),2)}%')\n",
    "    print(f'{key} Val Loss: {round(val_loss,4)}')\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m3_t1_history saved in /floyd/home/\n",
      "m3_t2_history saved in /floyd/home/\n",
      "m3_t3_history saved in /floyd/home/\n",
      "m3_t4_history saved in /floyd/home/\n",
      "m3_t5_history saved in /floyd/home/\n",
      "m3_t6_history saved in /floyd/home/\n",
      "m3_t7_history saved in /floyd/home/\n"
     ]
    }
   ],
   "source": [
    "# saving training histories\n",
    "for key, value in models_dict.items():\n",
    "    with open(f'{model_path}{key}_history', 'wb') as file_pi:\n",
    "        pickle.dump(value[1].history, file_pi)\n",
    "    print(f'{key}_history saved in {model_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
