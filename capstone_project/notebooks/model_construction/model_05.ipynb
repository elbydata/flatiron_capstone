{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the construction and training of the model iterations and various experiments. The notebook is split up into four sections: training mode selection (where the model will run), set-up, model constrution, and training. \n",
    "\n",
    "Evaluation will take place in the notebook *model_optimization_and_evaluation.ipynb* found in the *notebooks* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Training Mode Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, specify the training mode for the model. This will determine the location from which the source data is drawn, and to which the trained models (and training histories) are saved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **training_mode = 'floydhub'** (runs on Floydhub)\n",
    "- **training_mode = 'local'** (runs on local disk and processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select training mode\n",
    "training_mode = 'floydhub'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory base paths\n",
    "data_path_local = '../../data/0002_array_data/train_data/'\n",
    "model_path_local = '../../notebooks/model_construction/saved_models/'\n",
    "data_path_floydhub = '/floyd/input/capstone_mushrooms/'\n",
    "model_path_floydhub = '/floyd/home/'\n",
    "\n",
    "# setting directory paths based on training mode selection\n",
    "if training_mode == 'floydhub':\n",
    "    data_path = data_path_floydhub\n",
    "    model_path = model_path_floydhub\n",
    "elif training_mode == 'local':\n",
    "    data_path = data_path_local\n",
    "    model_path = model_path_local\n",
    "else:\n",
    "    raise Exception('Please choose valid training mode: \"floydhub\" or \"local\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the training and validation data subsets\n",
    "X_train = np.load(f'{data_path}X_train_data.npy')\n",
    "y_train = np.load(f'{data_path}y_train_data.npy')\n",
    "X_val = np.load(f'{data_path}X_val_data.npy')\n",
    "y_val = np.load(f'{data_path}y_val_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting training parameters\n",
    "batch_size = 8\n",
    "n_classes = 20\n",
    "n_epochs = 15\n",
    "img_shape = X_train.shape[1:]\n",
    "model_names = []\n",
    "model_list = []\n",
    "model_hists = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 1 - ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "elu_1 (ELU)                  (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "elu_2 (ELU)                  (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "elu_3 (ELU)                  (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "elu_4 (ELU)                  (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "elu_5 (ELU)                  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m5_t1 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m5_t1.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same'))\n",
    "m5_t1.add(layers.ELU(alpha=0.1))\n",
    "m5_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m5_t1.add(layers.Conv2D(64,(3,3), padding='same'))\n",
    "m5_t1.add(layers.ELU(alpha=0.1))\n",
    "m5_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m5_t1.add(layers.Conv2D(128,(3,3), padding='same'))\n",
    "m5_t1.add(layers.ELU(alpha=0.1))\n",
    "m5_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m5_t1.add(layers.Conv2D(256,(3,3), padding='same'))\n",
    "m5_t1.add(layers.ELU(alpha=0.1))\n",
    "m5_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m5_t1.add(layers.Flatten())\n",
    "m5_t1.add(layers.Dense(512))\n",
    "m5_t1.add(layers.ELU(alpha=0.1))\n",
    "m5_t1.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m5_t1.summary()\n",
    "model_names.append('m5_t1')\n",
    "model_list.append(m5_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 2 - PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 200, 200, 32)      1280000   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 100, 100, 64)      640000    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, 50, 50, 128)       320000    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "p_re_lu_4 (PReLU)            (None, 25, 25, 256)       160000    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "p_re_lu_5 (PReLU)            (None, 512)               512       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 21,674,068\n",
      "Trainable params: 21,674,068\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m5_t2 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m5_t2.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same'))\n",
    "m5_t2.add(layers.PReLU())\n",
    "m5_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m5_t2.add(layers.Conv2D(64,(3,3), padding='same'))\n",
    "m5_t2.add(layers.PReLU())\n",
    "m5_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m5_t2.add(layers.Conv2D(128,(3,3), padding='same'))\n",
    "m5_t2.add(layers.PReLU())\n",
    "m5_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m5_t2.add(layers.Conv2D(256,(3,3), padding='same'))\n",
    "m5_t2.add(layers.PReLU())\n",
    "m5_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m5_t2.add(layers.Flatten())\n",
    "m5_t2.add(layers.Dense(512))\n",
    "m5_t2.add(layers.PReLU())\n",
    "m5_t2.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m5_t2.summary()\n",
    "model_names.append('m5_t2')\n",
    "model_list.append(m5_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 3 - Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m5_t3 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m5_t3.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same'))\n",
    "m5_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m5_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m5_t3.add(layers.Conv2D(64,(3,3), padding='same'))\n",
    "m5_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m5_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m5_t3.add(layers.Conv2D(128,(3,3), padding='same'))\n",
    "m5_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m5_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m5_t3.add(layers.Conv2D(256,(3,3), padding='same'))\n",
    "m5_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m5_t3.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m5_t3.add(layers.Flatten())\n",
    "m5_t3.add(layers.Dense(512))\n",
    "m5_t3.add(layers.LeakyReLU(alpha=0.1))\n",
    "m5_t3.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m5_t3.summary()\n",
    "model_names.append('m5_t3')\n",
    "model_list.append(m5_t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 4 - Swish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing additional libraries\n",
    "from keras import backend as K\n",
    "\n",
    "# updating activations class with swish function\n",
    "class Swish(layers.Activation):   \n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Swish, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'swish'\n",
    "\n",
    "# defining swish function        \n",
    "def swish(x):\n",
    "    return (K.sigmoid(x)*x)\n",
    "\n",
    "# updating custom objects with swish function\n",
    "get_custom_objects().update({'swish': Swish(swish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m5_t4 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m5_t4.add(layers.Conv2D(32,(3,3), activation='swish', input_shape=img_shape, padding='same'))\n",
    "m5_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m5_t4.add(layers.Conv2D(64,(3,3), activation='swish', padding='same'))\n",
    "m5_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m5_t4.add(layers.Conv2D(128,(3,3), activation='swish', padding='same'))\n",
    "m5_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m5_t4.add(layers.Conv2D(256,(3,3), activation='swish', padding='same'))\n",
    "m5_t4.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m5_t4.add(layers.Flatten())\n",
    "m5_t4.add(layers.Dense(512, activation='swish'))\n",
    "m5_t4.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m5_t4.summary()\n",
    "model_names.append('m5_t4')\n",
    "model_list.append(m5_t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up standardization and augmentation parameters\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.3,\n",
    "                                   height_shift_range=0.3,\n",
    "                                   shear_range=0.3,\n",
    "                                   zoom_range=0.3,\n",
    "                                   fill_mode='nearest',\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 416 ms, sys: 1.3 s, total: 1.72 s\n",
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data standardization and augmentation\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling loss functions\n",
    "m5_t1.compile(loss='categorical_crossentropy',optimizer='adamax',metrics=['acc'])\n",
    "m5_t2.compile(loss='categorical_crossentropy',optimizer='adamax',metrics=['acc'])\n",
    "m5_t3.compile(loss='categorical_crossentropy',optimizer='adamax',metrics=['acc'])\n",
    "m5_t4.compile(loss='categorical_crossentropy',optimizer='adamax',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1013/1013 [==============================] - 92s 91ms/step - loss: 2.6411 - acc: 0.1696 - val_loss: 2.2830 - val_acc: 0.3131\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.31312, saving model to /floyd/home/m5_t1.h5\n",
      "Epoch 2/15\n",
      "1013/1013 [==============================] - 90s 89ms/step - loss: 2.2936 - acc: 0.2679 - val_loss: 2.7552 - val_acc: 0.3429\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.31312 to 0.34289, saving model to /floyd/home/m5_t1.h5\n",
      "Epoch 3/15\n",
      "1013/1013 [==============================] - 90s 89ms/step - loss: 2.1731 - acc: 0.3004 - val_loss: 2.5141 - val_acc: 0.3504\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.34289 to 0.35037, saving model to /floyd/home/m5_t1.h5\n",
      "Epoch 4/15\n",
      "1013/1013 [==============================] - 90s 89ms/step - loss: 2.0734 - acc: 0.3346 - val_loss: 1.3026 - val_acc: 0.4514\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.35037 to 0.45137, saving model to /floyd/home/m5_t1.h5\n",
      "Epoch 5/15\n",
      "1013/1013 [==============================] - 90s 89ms/step - loss: 1.9871 - acc: 0.3632 - val_loss: 2.4632 - val_acc: 0.4165\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.45137\n",
      "Epoch 6/15\n",
      "1013/1013 [==============================] - 90s 89ms/step - loss: 1.9149 - acc: 0.3895 - val_loss: 1.1587 - val_acc: 0.4551\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.45137 to 0.45511, saving model to /floyd/home/m5_t1.h5\n",
      "Epoch 7/15\n",
      "1013/1013 [==============================] - 90s 89ms/step - loss: 1.8374 - acc: 0.4147 - val_loss: 1.3644 - val_acc: 0.4875\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.45511 to 0.48753, saving model to /floyd/home/m5_t1.h5\n",
      "Epoch 8/15\n",
      "1013/1013 [==============================] - 90s 89ms/step - loss: 1.7957 - acc: 0.4273 - val_loss: 1.5905 - val_acc: 0.5012\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.48753 to 0.50125, saving model to /floyd/home/m5_t1.h5\n",
      "Epoch 9/15\n",
      "1013/1013 [==============================] - 90s 89ms/step - loss: 1.7407 - acc: 0.4430 - val_loss: 1.3630 - val_acc: 0.5162\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.50125 to 0.51621, saving model to /floyd/home/m5_t1.h5\n",
      "Epoch 10/15\n",
      "1013/1013 [==============================] - 90s 89ms/step - loss: 1.7008 - acc: 0.4570 - val_loss: 2.3506 - val_acc: 0.5224\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.51621 to 0.52244, saving model to /floyd/home/m5_t1.h5\n",
      "Epoch 11/15\n",
      "1013/1013 [==============================] - 90s 89ms/step - loss: 1.6600 - acc: 0.4742 - val_loss: 0.8476 - val_acc: 0.5224\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.52244\n",
      "Epoch 12/15\n",
      "1013/1013 [==============================] - 90s 88ms/step - loss: 1.6101 - acc: 0.4878 - val_loss: 1.0342 - val_acc: 0.4988\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.52244\n",
      "Epoch 13/15\n",
      "1013/1013 [==============================] - 90s 88ms/step - loss: 1.5761 - acc: 0.4954 - val_loss: 1.2018 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.52244\n",
      "Epoch 14/15\n",
      "1013/1013 [==============================] - 90s 88ms/step - loss: 1.5282 - acc: 0.5141 - val_loss: 1.1414 - val_acc: 0.5486\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.52244 to 0.54863, saving model to /floyd/home/m5_t1.h5\n",
      "Epoch 15/15\n",
      "1013/1013 [==============================] - 90s 89ms/step - loss: 1.5101 - acc: 0.5181 - val_loss: 2.2265 - val_acc: 0.4975\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.54863\n",
      "CPU times: user 31min 30s, sys: 5min 38s, total: 37min 8s\n",
      "Wall time: 22min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m5_t1_cp = ModelCheckpoint(filepath=f'{model_path}m5_t1.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m5_t1_history = m5_t1.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m5_t1_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m5_t1_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.7400 - acc: 0.1305 - val_loss: 2.2188 - val_acc: 0.2030\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.20297, saving model to /floyd/home/m5_t2.h5\n",
      "Epoch 2/15\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.4536 - acc: 0.1983 - val_loss: 2.0447 - val_acc: 0.2930\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.20297 to 0.29302, saving model to /floyd/home/m5_t2.h5\n",
      "Epoch 3/15\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.2821 - acc: 0.2599 - val_loss: 2.1920 - val_acc: 0.3416\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.29302 to 0.34165, saving model to /floyd/home/m5_t2.h5\n",
      "Epoch 4/15\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.1527 - acc: 0.3025 - val_loss: 2.0418 - val_acc: 0.4052\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.34165 to 0.40524, saving model to /floyd/home/m5_t2.h5\n",
      "Epoch 5/15\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.0537 - acc: 0.3377 - val_loss: 2.0796 - val_acc: 0.4252\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.40524 to 0.42519, saving model to /floyd/home/m5_t2.h5\n",
      "Epoch 6/15\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.9783 - acc: 0.3596 - val_loss: 1.2137 - val_acc: 0.4289\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.42519 to 0.42893, saving model to /floyd/home/m5_t2.h5\n",
      "Epoch 7/15\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.9131 - acc: 0.3874 - val_loss: 1.6307 - val_acc: 0.4738\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.42893 to 0.47382, saving model to /floyd/home/m5_t2.h5\n",
      "Epoch 8/15\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.8530 - acc: 0.4084 - val_loss: 2.9645 - val_acc: 0.4576\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.47382\n",
      "Epoch 9/15\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.7933 - acc: 0.4309 - val_loss: 1.2920 - val_acc: 0.4900\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.47382 to 0.49002, saving model to /floyd/home/m5_t2.h5\n",
      "Epoch 10/15\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.7470 - acc: 0.4431 - val_loss: 1.7897 - val_acc: 0.4825\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.49002\n",
      "Epoch 11/15\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.7083 - acc: 0.4562 - val_loss: 1.3105 - val_acc: 0.5200\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.49002 to 0.51995, saving model to /floyd/home/m5_t2.h5\n",
      "Epoch 12/15\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.6733 - acc: 0.4678 - val_loss: 1.5829 - val_acc: 0.4713\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.51995\n",
      "Epoch 13/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6335 - acc: 0.4720 - val_loss: 2.2267 - val_acc: 0.5362\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.51995 to 0.53616, saving model to /floyd/home/m5_t2.h5\n",
      "Epoch 14/15\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.6164 - acc: 0.4816 - val_loss: 1.2160 - val_acc: 0.5287\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.53616\n",
      "Epoch 15/15\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 1.5549 - acc: 0.5043 - val_loss: 0.7197 - val_acc: 0.5436\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.53616 to 0.54364, saving model to /floyd/home/m5_t2.h5\n",
      "CPU times: user 29min 27s, sys: 4min 10s, total: 33min 37s\n",
      "Wall time: 20min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m5_t2_cp = ModelCheckpoint(filepath=f'{model_path}m5_t2.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m5_t2_history = m5_t2.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m5_t2_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m5_t2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.7005 - acc: 0.1520 - val_loss: 1.5096 - val_acc: 0.2921\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.29208, saving model to /floyd/home/m5_t3.h5\n",
      "Epoch 2/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.3114 - acc: 0.2533 - val_loss: 1.8426 - val_acc: 0.3716\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.29208 to 0.37157, saving model to /floyd/home/m5_t3.h5\n",
      "Epoch 3/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.1803 - acc: 0.2893 - val_loss: 1.9939 - val_acc: 0.4065\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.37157 to 0.40648, saving model to /floyd/home/m5_t3.h5\n",
      "Epoch 4/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.0828 - acc: 0.3290 - val_loss: 1.6030 - val_acc: 0.4401\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.40648 to 0.44015, saving model to /floyd/home/m5_t3.h5\n",
      "Epoch 5/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.9941 - acc: 0.3610 - val_loss: 1.5362 - val_acc: 0.4302\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.44015\n",
      "Epoch 6/15\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.9322 - acc: 0.3807 - val_loss: 2.6227 - val_acc: 0.4564\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.44015 to 0.45636, saving model to /floyd/home/m5_t3.h5\n",
      "Epoch 7/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.8703 - acc: 0.3975 - val_loss: 0.9712 - val_acc: 0.5237\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.45636 to 0.52369, saving model to /floyd/home/m5_t3.h5\n",
      "Epoch 8/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.8221 - acc: 0.4184 - val_loss: 1.3073 - val_acc: 0.5175\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.52369\n",
      "Epoch 9/15\n",
      "1013/1013 [==============================] - 77s 76ms/step - loss: 1.7676 - acc: 0.4384 - val_loss: 1.4498 - val_acc: 0.4389\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.52369\n",
      "Epoch 10/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.7040 - acc: 0.4558 - val_loss: 1.1810 - val_acc: 0.5374\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.52369 to 0.53741, saving model to /floyd/home/m5_t3.h5\n",
      "Epoch 11/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6774 - acc: 0.4731 - val_loss: 1.1354 - val_acc: 0.5611\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.53741 to 0.56110, saving model to /floyd/home/m5_t3.h5\n",
      "Epoch 12/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6465 - acc: 0.4810 - val_loss: 1.0539 - val_acc: 0.5686\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.56110 to 0.56858, saving model to /floyd/home/m5_t3.h5\n",
      "Epoch 13/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.6140 - acc: 0.4889 - val_loss: 1.0803 - val_acc: 0.5561\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.56858\n",
      "Epoch 14/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.5652 - acc: 0.5062 - val_loss: 1.6963 - val_acc: 0.6097\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.56858 to 0.60973, saving model to /floyd/home/m5_t3.h5\n",
      "Epoch 15/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.5285 - acc: 0.5143 - val_loss: 3.1124 - val_acc: 0.5312\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.60973\n",
      "CPU times: user 27min 25s, sys: 3min 5s, total: 30min 31s\n",
      "Wall time: 19min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m5_t3_cp = ModelCheckpoint(filepath=f'{model_path}m5_t3.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m5_t3_history = m5_t3.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m5_t3_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m5_t3_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.6822 - acc: 0.1537 - val_loss: 2.0849 - val_acc: 0.2921\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.29208, saving model to /floyd/home/m5_t4.h5\n",
      "Epoch 2/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.4595 - acc: 0.2110 - val_loss: 1.0718 - val_acc: 0.3441\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.29208 to 0.34414, saving model to /floyd/home/m5_t4.h5\n",
      "Epoch 3/15\n",
      "1013/1013 [==============================] - 79s 78ms/step - loss: 2.2976 - acc: 0.2617 - val_loss: 2.2324 - val_acc: 0.3504\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.34414 to 0.35037, saving model to /floyd/home/m5_t4.h5\n",
      "Epoch 4/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.2122 - acc: 0.2912 - val_loss: 2.4057 - val_acc: 0.4077\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.35037 to 0.40773, saving model to /floyd/home/m5_t4.h5\n",
      "Epoch 5/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.1311 - acc: 0.3160 - val_loss: 2.0730 - val_acc: 0.3828\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.40773\n",
      "Epoch 6/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.0744 - acc: 0.3296 - val_loss: 1.6217 - val_acc: 0.4052\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.40773\n",
      "Epoch 7/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 2.0309 - acc: 0.3554 - val_loss: 2.0540 - val_acc: 0.4589\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.40773 to 0.45885, saving model to /floyd/home/m5_t4.h5\n",
      "Epoch 8/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.9734 - acc: 0.3715 - val_loss: 2.3769 - val_acc: 0.4239\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.45885\n",
      "Epoch 9/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.9145 - acc: 0.3880 - val_loss: 3.0341 - val_acc: 0.4925\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.45885 to 0.49252, saving model to /floyd/home/m5_t4.h5\n",
      "Epoch 10/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.9002 - acc: 0.3943 - val_loss: 1.5214 - val_acc: 0.4551\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.49252\n",
      "Epoch 11/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.8488 - acc: 0.4177 - val_loss: 2.0146 - val_acc: 0.4701\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.49252\n",
      "Epoch 12/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.8108 - acc: 0.4257 - val_loss: 2.0605 - val_acc: 0.5150\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.49252 to 0.51496, saving model to /floyd/home/m5_t4.h5\n",
      "Epoch 13/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.7877 - acc: 0.4272 - val_loss: 1.3818 - val_acc: 0.4963\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.51496\n",
      "Epoch 14/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.7575 - acc: 0.4421 - val_loss: 2.1717 - val_acc: 0.4838\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.51496\n",
      "Epoch 15/15\n",
      "1013/1013 [==============================] - 78s 77ms/step - loss: 1.7406 - acc: 0.4548 - val_loss: 1.9747 - val_acc: 0.4676\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.51496\n",
      "CPU times: user 27min 47s, sys: 3min 16s, total: 31min 3s\n",
      "Wall time: 19min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m5_t4_cp = ModelCheckpoint(filepath=f'{model_path}m5_t4.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m5_t4_history = m5_t4.fit(train_generator,\n",
    "                                steps_per_epoch=len(X_train)//batch_size,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m5_t4_cp],\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=len(X_val)//batch_size)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m5_t4_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary for model names, models, and histories from respective lists\n",
    "models_dict = {i:[j,k] for i,j,k in zip(model_names,model_list,model_hists)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 2s 20ms/step\n",
      "m5_t1 Val Accuracy: 54.57%\n",
      "m5_t1 Val Loss: 0.055\n",
      "---\n",
      "102/102 [==============================] - 2s 23ms/step\n",
      "m5_t2 Val Accuracy: 54.94%\n",
      "m5_t2 Val Loss: 1.1891\n",
      "---\n",
      "102/102 [==============================] - 2s 18ms/step\n",
      "m5_t3 Val Accuracy: 59.75%\n",
      "m5_t3 Val Loss: 0.2868\n",
      "---\n",
      "102/102 [==============================] - 2s 17ms/step\n",
      "m5_t4 Val Accuracy: 51.6%\n",
      "m5_t4 Val Loss: 0.4262\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# evaluating models on validation set\n",
    "for key, value in models_dict.items():\n",
    "    model = models.load_model(f'{model_path}{key}.h5')\n",
    "    (val_loss, val_accuracy) = model.evaluate(val_generator,verbose=1)\n",
    "    print(f'{key} Val Accuracy: {round((val_accuracy*100),2)}%')\n",
    "    print(f'{key} Val Loss: {round(val_loss,4)}')\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m5_t1_history saved in /floyd/home/\n",
      "m5_t2_history saved in /floyd/home/\n",
      "m5_t3_history saved in /floyd/home/\n",
      "m5_t4_history saved in /floyd/home/\n"
     ]
    }
   ],
   "source": [
    "# saving training histories\n",
    "for key, value in models_dict.items():\n",
    "    with open(f'{model_path}{key}_history', 'wb') as file_pi:\n",
    "        pickle.dump(value[1].history, file_pi)\n",
    "    print(f'{key}_history saved in {model_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
