{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 7: Batch Size Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the construction and training of the model iterations and various experiments. The notebook is split up into four sections: training mode selection (where the model will run), set-up, model constrution, and training. \n",
    "\n",
    "Evaluation will take place in the *model_optimization_and_evaluation.ipynb* notebook found in the *notebooks* folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import applications \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Training Mode Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, specify the training mode for the model. This will determine the location from which the source data is drawn, and to which the trained models (and training histories) are saved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **training_mode = 'floydhub'** (runs on Floydhub)\n",
    "- **training_mode = 'local'** (runs on local disk and processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select training mode\n",
    "training_mode = 'floydhub'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory base paths\n",
    "data_path_local = '../../data/0002_array_data/train_data/'\n",
    "model_path_local = '../../notebooks/model_construction/saved_models/'\n",
    "data_path_floydhub = '/floyd/input/capstone_mushrooms/'\n",
    "model_path_floydhub = '/floyd/home/'\n",
    "\n",
    "# setting directory paths based on training mode selection\n",
    "if training_mode == 'floydhub':\n",
    "    data_path = data_path_floydhub\n",
    "    model_path = model_path_floydhub\n",
    "elif training_mode == 'local':\n",
    "    data_path = data_path_local\n",
    "    model_path = model_path_local\n",
    "else:\n",
    "    raise Exception('Please choose valid training mode: \"floydhub\" or \"local\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the training and validation data subsets\n",
    "X_train = np.load(f'{data_path}X_train_data.npy')\n",
    "y_train = np.load(f'{data_path}y_train_data.npy')\n",
    "X_val = np.load(f'{data_path}X_val_data.npy')\n",
    "y_val = np.load(f'{data_path}y_val_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting training parameters\n",
    "n_classes = 20\n",
    "n_epochs = 30\n",
    "img_shape = X_train.shape[1:]\n",
    "model_names = []\n",
    "model_list = []\n",
    "model_hists = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m7_t1 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m7_t1.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same'))\n",
    "m7_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m7_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m7_t1.add(layers.Conv2D(64,(3,3), padding='same'))\n",
    "m7_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m7_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m7_t1.add(layers.Conv2D(128,(3,3), padding='same'))\n",
    "m7_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m7_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m7_t1.add(layers.Conv2D(256,(3,3), padding='same'))\n",
    "m7_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m7_t1.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m7_t1.add(layers.Flatten())\n",
    "m7_t1.add(layers.Dense(512))\n",
    "m7_t1.add(layers.LeakyReLU(alpha=0.1))\n",
    "m7_t1.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m7_t1.summary()\n",
    "model_names.append('m7_t1')\n",
    "model_list.append(m7_t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 200, 200, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 100, 100, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 50, 50, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,273,556\n",
      "Trainable params: 19,273,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model architecture\n",
    "m7_t2 = models.Sequential()\n",
    "\n",
    "# convolution/max pool stacks\n",
    "m7_t2.add(layers.Conv2D(32,(3,3), input_shape=img_shape, padding='same'))\n",
    "m7_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m7_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m7_t2.add(layers.Conv2D(64,(3,3), padding='same'))\n",
    "m7_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m7_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m7_t2.add(layers.Conv2D(128,(3,3), padding='same'))\n",
    "m7_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m7_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "m7_t2.add(layers.Conv2D(256,(3,3), padding='same'))\n",
    "m7_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m7_t2.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# fully connected layers\n",
    "m7_t2.add(layers.Flatten())\n",
    "m7_t2.add(layers.Dense(512))\n",
    "m7_t2.add(layers.LeakyReLU(alpha=0.1))\n",
    "m7_t2.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# reviewing the model architecture and adding model and name to list\n",
    "m7_t2.summary()\n",
    "model_names.append('m7_t2')\n",
    "model_list.append(m7_t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up standardization and augmentation parameters\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.3,\n",
    "                                   height_shift_range=0.3,\n",
    "                                   shear_range=0.3,\n",
    "                                   zoom_range=0.3,\n",
    "                                   fill_mode='nearest',\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 763 ms, sys: 1.91 s, total: 2.67 s\n",
      "Wall time: 2.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data standardization and augmentation\n",
    "train_generator_1 = train_datagen.flow(X_train, y_train, batch_size=4)\n",
    "train_generator_2 = train_datagen.flow(X_train, y_train, batch_size=2)\n",
    "val_generator_1 = val_datagen.flow(X_val, y_val, batch_size=4)\n",
    "val_generator_2 = val_datagen.flow(X_val, y_val, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up optimizer\n",
    "opt = optimizers.Adamax(learning_rate=1e-3)\n",
    "\n",
    "# compiling loss functions\n",
    "m7_t1.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "m7_t2.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2027/2027 [==============================] - 106s 52ms/step - loss: 2.5904 - acc: 0.1830 - val_loss: 2.3221 - val_acc: 0.3082\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.30817, saving model to /floyd/home/m7_t1.h5\n",
      "Epoch 2/30\n",
      "2027/2027 [==============================] - 79s 39ms/step - loss: 2.2449 - acc: 0.2796 - val_loss: 1.5651 - val_acc: 0.3759\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.30817 to 0.37593, saving model to /floyd/home/m7_t1.h5\n",
      "Epoch 3/30\n",
      "2027/2027 [==============================] - 79s 39ms/step - loss: 2.1139 - acc: 0.3218 - val_loss: 1.4996 - val_acc: 0.3697\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.37593\n",
      "Epoch 4/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 2.0009 - acc: 0.3606 - val_loss: 2.5438 - val_acc: 0.4404\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.37593 to 0.44045, saving model to /floyd/home/m7_t1.h5\n",
      "Epoch 5/30\n",
      "2027/2027 [==============================] - 79s 39ms/step - loss: 1.9046 - acc: 0.3949 - val_loss: 1.6985 - val_acc: 0.4950\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.44045 to 0.49504, saving model to /floyd/home/m7_t1.h5\n",
      "Epoch 6/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.8445 - acc: 0.4135 - val_loss: 2.0528 - val_acc: 0.5149\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.49504 to 0.51489, saving model to /floyd/home/m7_t1.h5\n",
      "Epoch 7/30\n",
      "2027/2027 [==============================] - 79s 39ms/step - loss: 1.7700 - acc: 0.4336 - val_loss: 1.3728 - val_acc: 0.5744\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.51489 to 0.57444, saving model to /floyd/home/m7_t1.h5\n",
      "Epoch 8/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.7376 - acc: 0.4566 - val_loss: 2.3892 - val_acc: 0.5695\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.57444\n",
      "Epoch 9/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.6883 - acc: 0.4652 - val_loss: 0.7948 - val_acc: 0.5347\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.57444\n",
      "Epoch 10/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.6305 - acc: 0.4793 - val_loss: 0.7948 - val_acc: 0.5298\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.57444\n",
      "Epoch 11/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.6084 - acc: 0.4863 - val_loss: 0.9858 - val_acc: 0.5422\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.57444\n",
      "Epoch 12/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.5776 - acc: 0.4985 - val_loss: 0.8844 - val_acc: 0.5459\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.57444\n",
      "Epoch 13/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.5513 - acc: 0.5086 - val_loss: 1.9161 - val_acc: 0.5906\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.57444 to 0.59057, saving model to /floyd/home/m7_t1.h5\n",
      "Epoch 14/30\n",
      "2027/2027 [==============================] - 79s 39ms/step - loss: 1.5057 - acc: 0.5215 - val_loss: 1.3374 - val_acc: 0.5931\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.59057 to 0.59305, saving model to /floyd/home/m7_t1.h5\n",
      "Epoch 15/30\n",
      "2027/2027 [==============================] - 79s 39ms/step - loss: 1.4819 - acc: 0.5331 - val_loss: 0.9059 - val_acc: 0.6092\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.59305 to 0.60918, saving model to /floyd/home/m7_t1.h5\n",
      "Epoch 16/30\n",
      "2027/2027 [==============================] - 79s 39ms/step - loss: 1.4419 - acc: 0.5428 - val_loss: 1.0351 - val_acc: 0.5844\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.60918\n",
      "Epoch 17/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.4196 - acc: 0.5566 - val_loss: 1.7426 - val_acc: 0.6377\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.60918 to 0.63772, saving model to /floyd/home/m7_t1.h5\n",
      "Epoch 18/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.3856 - acc: 0.5598 - val_loss: 0.1964 - val_acc: 0.5856\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.63772\n",
      "Epoch 19/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.3793 - acc: 0.5673 - val_loss: 0.0940 - val_acc: 0.6203\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.63772\n",
      "Epoch 20/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.3459 - acc: 0.5705 - val_loss: 0.0246 - val_acc: 0.6042\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.63772\n",
      "Epoch 21/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.3415 - acc: 0.5739 - val_loss: 2.5704 - val_acc: 0.6166\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.63772\n",
      "Epoch 22/30\n",
      "2027/2027 [==============================] - 78s 38ms/step - loss: 1.2993 - acc: 0.5878 - val_loss: 1.1481 - val_acc: 0.5757\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.63772\n",
      "Epoch 23/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.2681 - acc: 0.5934 - val_loss: 0.4061 - val_acc: 0.6266\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.63772\n",
      "Epoch 24/30\n",
      "2027/2027 [==============================] - 79s 39ms/step - loss: 1.2643 - acc: 0.6035 - val_loss: 2.3802 - val_acc: 0.6216\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.63772\n",
      "Epoch 25/30\n",
      "2027/2027 [==============================] - 79s 39ms/step - loss: 1.2242 - acc: 0.6056 - val_loss: 2.3517 - val_acc: 0.6017\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.63772\n",
      "Epoch 26/30\n",
      "2027/2027 [==============================] - 79s 39ms/step - loss: 1.2197 - acc: 0.6159 - val_loss: 2.4008 - val_acc: 0.6315\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.63772\n",
      "Epoch 27/30\n",
      "2027/2027 [==============================] - 79s 39ms/step - loss: 1.1737 - acc: 0.6297 - val_loss: 1.4819 - val_acc: 0.6303\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.63772\n",
      "Epoch 28/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.1776 - acc: 0.6214 - val_loss: 1.8591 - val_acc: 0.5571\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.63772\n",
      "Epoch 29/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.1803 - acc: 0.6285 - val_loss: 0.3949 - val_acc: 0.6762\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.63772 to 0.67618, saving model to /floyd/home/m7_t1.h5\n",
      "Epoch 30/30\n",
      "2027/2027 [==============================] - 78s 39ms/step - loss: 1.1396 - acc: 0.6347 - val_loss: 0.2609 - val_acc: 0.6241\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.67618\n",
      "CPU times: user 1h 1min 42s, sys: 9min 23s, total: 1h 11min 6s\n",
      "Wall time: 39min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m7_t1_cp = ModelCheckpoint(filepath=f'{model_path}m7_t1.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m7_t1_history = m7_t1.fit(train_generator_1,\n",
    "                                steps_per_epoch=len(X_train)//4,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m7_t1_cp],\n",
    "                                validation_data=val_generator_1,\n",
    "                                validation_steps=len(X_val)//4)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m7_t1_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4054/4054 [==============================] - 126s 31ms/step - loss: 2.5713 - acc: 0.1806 - val_loss: 0.7337 - val_acc: 0.2938\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.29383, saving model to /floyd/home/m7_t2.h5\n",
      "Epoch 2/30\n",
      "4054/4054 [==============================] - 126s 31ms/step - loss: 2.2602 - acc: 0.2796 - val_loss: 1.0933 - val_acc: 0.3753\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.29383 to 0.37531, saving model to /floyd/home/m7_t2.h5\n",
      "Epoch 3/30\n",
      "4054/4054 [==============================] - 126s 31ms/step - loss: 2.1060 - acc: 0.3162 - val_loss: 3.3888 - val_acc: 0.3926\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.37531 to 0.39259, saving model to /floyd/home/m7_t2.h5\n",
      "Epoch 4/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 2.0086 - acc: 0.3535 - val_loss: 2.7699 - val_acc: 0.4556\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.39259 to 0.45556, saving model to /floyd/home/m7_t2.h5\n",
      "Epoch 5/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.9325 - acc: 0.3773 - val_loss: 0.3893 - val_acc: 0.4901\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.45556 to 0.49012, saving model to /floyd/home/m7_t2.h5\n",
      "Epoch 6/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.8643 - acc: 0.3987 - val_loss: 1.4061 - val_acc: 0.4716\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.49012\n",
      "Epoch 7/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.8134 - acc: 0.4214 - val_loss: 1.1036 - val_acc: 0.5247\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.49012 to 0.52469, saving model to /floyd/home/m7_t2.h5\n",
      "Epoch 8/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.7621 - acc: 0.4431 - val_loss: 0.7961 - val_acc: 0.5136\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.52469\n",
      "Epoch 9/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.7178 - acc: 0.4539 - val_loss: 1.9269 - val_acc: 0.5025\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.52469\n",
      "Epoch 10/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.6776 - acc: 0.4656 - val_loss: 0.2529 - val_acc: 0.5259\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.52469 to 0.52593, saving model to /floyd/home/m7_t2.h5\n",
      "Epoch 11/30\n",
      "4054/4054 [==============================] - 126s 31ms/step - loss: 1.6416 - acc: 0.4835 - val_loss: 2.4758 - val_acc: 0.5272\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.52593 to 0.52716, saving model to /floyd/home/m7_t2.h5\n",
      "Epoch 12/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.6167 - acc: 0.4900 - val_loss: 1.1657 - val_acc: 0.5235\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.52716\n",
      "Epoch 13/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.5863 - acc: 0.5069 - val_loss: 1.4164 - val_acc: 0.5605\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.52716 to 0.56049, saving model to /floyd/home/m7_t2.h5\n",
      "Epoch 14/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.5618 - acc: 0.5057 - val_loss: 0.1720 - val_acc: 0.5914\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.56049 to 0.59136, saving model to /floyd/home/m7_t2.h5\n",
      "Epoch 15/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.5282 - acc: 0.5187 - val_loss: 1.4941 - val_acc: 0.5222\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.59136\n",
      "Epoch 16/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.5069 - acc: 0.5241 - val_loss: 0.6185 - val_acc: 0.5975\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.59136 to 0.59753, saving model to /floyd/home/m7_t2.h5\n",
      "Epoch 17/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.4832 - acc: 0.5271 - val_loss: 2.1971 - val_acc: 0.5778\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.59753\n",
      "Epoch 18/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.4553 - acc: 0.5434 - val_loss: 0.4799 - val_acc: 0.5049\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.59753\n",
      "Epoch 19/30\n",
      "4054/4054 [==============================] - 126s 31ms/step - loss: 1.4347 - acc: 0.5486 - val_loss: 1.0645 - val_acc: 0.6037\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.59753 to 0.60370, saving model to /floyd/home/m7_t2.h5\n",
      "Epoch 20/30\n",
      "4054/4054 [==============================] - 126s 31ms/step - loss: 1.3945 - acc: 0.5611 - val_loss: 1.1083 - val_acc: 0.5086\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.60370\n",
      "Epoch 21/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.4017 - acc: 0.5613 - val_loss: 1.0509 - val_acc: 0.6099\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.60370 to 0.60988, saving model to /floyd/home/m7_t2.h5\n",
      "Epoch 22/30\n",
      "4054/4054 [==============================] - 126s 31ms/step - loss: 1.3790 - acc: 0.5661 - val_loss: 2.6546 - val_acc: 0.5988\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.60988\n",
      "Epoch 23/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.3503 - acc: 0.5739 - val_loss: 2.6232 - val_acc: 0.5494\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.60988\n",
      "Epoch 24/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.3230 - acc: 0.5856 - val_loss: 1.7568 - val_acc: 0.6272\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.60988 to 0.62716, saving model to /floyd/home/m7_t2.h5\n",
      "Epoch 25/30\n",
      "4054/4054 [==============================] - 126s 31ms/step - loss: 1.3222 - acc: 0.5828 - val_loss: 1.0583 - val_acc: 0.6272\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.62716\n",
      "Epoch 26/30\n",
      "4054/4054 [==============================] - 126s 31ms/step - loss: 1.3066 - acc: 0.5930 - val_loss: 0.6933 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.62716\n",
      "Epoch 27/30\n",
      "4054/4054 [==============================] - 126s 31ms/step - loss: 1.2752 - acc: 0.5969 - val_loss: 1.0654 - val_acc: 0.6185\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.62716\n",
      "Epoch 28/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.2706 - acc: 0.6014 - val_loss: 0.8845 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.62716 to 0.65432, saving model to /floyd/home/m7_t2.h5\n",
      "Epoch 29/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.2538 - acc: 0.6085 - val_loss: 1.9904 - val_acc: 0.5593\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.65432\n",
      "Epoch 30/30\n",
      "4054/4054 [==============================] - 125s 31ms/step - loss: 1.2268 - acc: 0.6121 - val_loss: 1.2645 - val_acc: 0.5926\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.65432\n",
      "CPU times: user 1h 20min 45s, sys: 15min 32s, total: 1h 36min 17s\n",
      "Wall time: 1h 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# setting up model saving checkpoints\n",
    "m7_t2_cp = ModelCheckpoint(filepath=f'{model_path}m7_t2.h5',\n",
    "                              monitor='val_acc',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True)\n",
    "\n",
    "# fitting model\n",
    "m7_t2_history = m7_t2.fit(train_generator_2,\n",
    "                                steps_per_epoch=len(X_train)//2,\n",
    "                                epochs=n_epochs,\n",
    "                                callbacks=[m7_t2_cp],\n",
    "                                validation_data=val_generator_2,\n",
    "                                validation_steps=len(X_val)//2)\n",
    "\n",
    "# adding training history to list\n",
    "model_hists.append(m7_t2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary for model names, models, and histories from respective lists\n",
    "models_dict = {i:[j,k] for i,j,k in zip(model_names,model_list,model_hists)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 2s 10ms/step\n",
      "Val Accuracy 1: 62.84%\n",
      "Val Loss 1: 0.0756\n",
      "---\n",
      "405/405 [==============================] - 3s 7ms/step\n",
      "Val Accuracy 2: 59.26%\n",
      "Val Loss 2: 1.2645\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "(val_loss_1, val_accuracy_1) = m7_t1.evaluate(val_generator_1,verbose=1)\n",
    "print(f'Val Accuracy 1: {round((val_accuracy_1*100),2)}%')\n",
    "print(f'Val Loss 1: {round(val_loss_1,4)}')\n",
    "print('---')\n",
    "(val_loss_2, val_accuracy_2) = m7_t2.evaluate(val_generator_2,verbose=1)\n",
    "print(f'Val Accuracy 2: {round((val_accuracy_2*100),2)}%')\n",
    "print(f'Val Loss 2: {round(val_loss_2,4)}')\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m7_t1_history saved in /floyd/home/\n",
      "m7_t2_history saved in /floyd/home/\n"
     ]
    }
   ],
   "source": [
    "# saving training histories\n",
    "for key, value in models_dict.items():\n",
    "    with open(f'{model_path}{key}_history', 'wb') as file_pi:\n",
    "        pickle.dump(value[1].history, file_pi)\n",
    "    print(f'{key}_history saved in {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
